{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/work/cotterell/kdu/measureLM/data/YagoECQ\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "# from SPARQLWrapper import SPARQLWrapper2\n",
    "# from SPARQLWrapper.SPARQLExceptions import EndPointInternalError\n",
    "from collections import namedtuple\n",
    "import re\n",
    "from time import sleep\n",
    "from urllib.error import HTTPError\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# from preprocessing.utils import extract_name_from_yago_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicate = namedtuple(\"Predicate\", [\"uri\", \"kb_name\", \"relation\"])\n",
    "DATA_ROOT = \".\"\n",
    "PRED_URI_TO_S_OBJ_CLASSES_PATH = os.path.join(DATA_ROOT, \"yago_pred_uri_to_s_obj_classes.json\")\n",
    "PRED_URI_TO_SO_PAIRS_PATH = os.path.join(DATA_ROOT, \"yago_pred_uri_to_so_pairs_randomized_1k.json\")\n",
    "YAGO_QEC_PATH = os.path.join(DATA_ROOT, \"yago_qec.json\")\n",
    "TRY_QUERYING_MISSING_PREDS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name_from_yago_uri(uri: str):\n",
    "    is_reversed = False\n",
    "    if uri.startswith(\"reverse-\"):\n",
    "        uri = uri.split(\"reverse-\")[1]\n",
    "        is_reversed = True\n",
    "    pattern = r\"http://(?:www\\.)?([^\\/]+)\\.org\\/(.+)$\"\n",
    "    matches = re.match(pattern, uri)\n",
    "\n",
    "    if matches:\n",
    "        kb_domain = matches.group(1)\n",
    "        relation = matches.group(2)\n",
    "    else:\n",
    "        raise ValueError(f\"Could not find match containing kb_domain and relation for uri {uri}.\")\n",
    "\n",
    "    domain_to_name = {\"schema\": \"schema\", \"yago-knowledge\": \"yago\", \"w3\": \"w3\"}\n",
    "    kb_name = domain_to_name[kb_domain]\n",
    "    kb_name = (\"reverse-\" if is_reversed else \"\") + kb_name\n",
    "\n",
    "    return kb_name, relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# 1. Get all relevant predicates #\n",
    "##################################\n",
    "sparql = SPARQLWrapper2(\"https://yago-knowledge.org/sparql/query\")\n",
    "query_p = \"\"\"\n",
    "    SELECT DISTINCT ?p WHERE {\n",
    "     ?s ?p ?obj . \n",
    "    }  ORDER BY ?p\n",
    "\"\"\"\n",
    "\n",
    "# Sparql query\n",
    "sparql.setQuery(query_p)\n",
    "\n",
    "# Adding values\n",
    "relevant_preds: List[Predicate] = []\n",
    "ineligible_relations = [\"schema#fromClass\", \"schema#fromProperty\", \"logo\", \"image\"]\n",
    "\n",
    "for result in sparql.query().bindings:\n",
    "    uri = result[\"p\"].value\n",
    "    kb_name, relation = extract_name_from_yago_uri(uri)\n",
    "    if kb_name != \"w3\" and relation not in ineligible_relations:\n",
    "        relevant_preds.append(Predicate(uri=uri, kb_name=kb_name, relation=relation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pred_to_s_and_obj_types from file ./yago_pred_uri_to_s_obj_classes.json.\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "# 1b. Get all subject and object types for each predicate #\n",
    "###########################################################\n",
    "from SPARQLWrapper.SPARQLExceptions import QueryBadFormed\n",
    "query_single = \"\"\"\n",
    "    SELECT DISTINCT ?s ?obj WHERE {{\n",
    "     ?s <{}> ?obj . \n",
    "    }}  LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "query_superclasses = \"\"\"\n",
    "    SELECT DISTINCT ?superclasses WHERE {{\n",
    "     <{}> rdf:type/rdfs:subClassOf* ?superclasses .\n",
    "    }}  \n",
    "\"\"\"\n",
    "\n",
    "types = [\n",
    "    \"http://schema.org/CreativeWork\",\n",
    "    \"http://schema.org/Event\",\n",
    "    \"http://schema.org/Intangible\",\n",
    "    \"http://schema.org/Organization\",\n",
    "    \"http://schema.org/Person\",\n",
    "    \"http://schema.org/Place\",\n",
    "    \"http://schema.org/Product\",\n",
    "    \"http://schema.org/Taxon\",\n",
    "    \"http://schema.org/FictionalEntity\",\n",
    "]\n",
    "if os.path.exists(PRED_URI_TO_S_OBJ_CLASSES_PATH):\n",
    "    print(f\"Loading pred_to_s_and_obj_types from file {PRED_URI_TO_S_OBJ_CLASSES_PATH}.\")\n",
    "    with open(PRED_URI_TO_S_OBJ_CLASSES_PATH, \"r\") as f:\n",
    "        pred_to_s_and_obj_types_with_reverse = json.load(f)\n",
    "else:\n",
    "    pred_to_s_and_obj_types = dict()\n",
    "    for pred in relevant_preds:\n",
    "        concrete_query_single = query_single.format(pred.uri)\n",
    "        # print(query)\n",
    "        sparql.setQuery(concrete_query_single)\n",
    "        superclasses_s = []\n",
    "        superclasses_obj = []\n",
    "        for result in sparql.query().bindings:\n",
    "            s = result[\"s\"].value\n",
    "            obj = result[\"obj\"].value\n",
    "            try:\n",
    "                concrete_query_superclasses_s = query_superclasses.format(s)\n",
    "                sparql.setQuery(concrete_query_superclasses_s)\n",
    "                superclasses_s += [x[\"superclasses\"].value for x in sparql.query().bindings]\n",
    "            except QueryBadFormed as e:\n",
    "                print(\"Raising error for s:\", s)\n",
    "                # raise ValueError\n",
    "            try:\n",
    "                concrete_query_superclasses_obj = query_superclasses.format(obj)\n",
    "                sparql.setQuery(concrete_query_superclasses_obj)\n",
    "                superclasses_obj += [x[\"superclasses\"].value for x in sparql.query().bindings]\n",
    "            except QueryBadFormed:\n",
    "                print(\"Raising error for obj:\", obj)\n",
    "                # raise ValueError\n",
    "            \n",
    "        pred_to_s_and_obj_types[pred] = (set(superclasses_s), set(superclasses_obj))\n",
    "            \n",
    "    pred_to_s_and_obj_types = {k.uri: (list(s_set.intersection(types)), list(obj_set.intersection(types))) for k, (s_set, obj_set) in pred_to_s_and_obj_types.items()}\n",
    "    pred_to_s_and_obj_types_with_reverse = {**pred_to_s_and_obj_types, **{f\"reverse-{k}\": (obj, s) for k, (s, obj) in pred_to_s_and_obj_types.items()}}\n",
    "\n",
    "with open(PRED_URI_TO_S_OBJ_CLASSES_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(pred_to_s_and_obj_types_with_reverse, fp, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# 2. Extract all subject-object pairs for each pred in relevant preds #\n",
    "#######################################################################\n",
    "def get_so_pairs_for_pred(pred: Predicate) -> List[Tuple[str, str, str, str]]:\n",
    "    start_time = time.time()\n",
    "    print(f\"Querying {pred.uri}.\")\n",
    "    so_pairs = []\n",
    "\n",
    "    query = \"\"\"\n",
    "SELECT DISTINCT ?output_s ?output_obj ?s ?obj WHERE {{\n",
    "  ?s <{}> ?obj . # which predicate to use\n",
    "  OPTIONAL {{ \n",
    "    ?s rdfs:label ?s_label .\n",
    "    FILTER (LANG(?s_label) = 'en')\n",
    "  }} # Get the label (name) for the subject if it exists\n",
    "  BIND(COALESCE(?s_label, ?s) AS ?output_s) # if the label does not exist, stick with the URI\n",
    "  \n",
    "  OPTIONAL {{\n",
    "    ?obj rdfs:label ?obj_label . \n",
    "    FILTER (LANG(?obj_label) = 'en')\n",
    "  }} # Get the label (name) for the object if it exists\n",
    "  OPTIONAL {{\n",
    "    ?obj rdf:type ?obj_type . \n",
    "    ?obj_type rdfs:label ?obj_type_name .\n",
    "    FILTER (LANG(?obj_type_name) = 'en')\n",
    "  }} # get the name of the type for the object if the type exists\n",
    "  BIND(COALESCE(IF(STR(?obj_label) != \"Generic instance\", ?obj_label, ?obj_type_name), ?obj) AS ?output_obj) \n",
    "  # if the label exists, go with the label, but if it's \"Generic instance\", then go with the type; if that does not exist, then stick with the OG object.\n",
    "  BIND(MD5(CONCAT(STR(?s), STR(?obj))) AS ?sortkey) .\n",
    "}}\n",
    "ORDER BY ?sortkey\n",
    "LIMIT 1000\n",
    "\"\"\".format(\n",
    "        pred.uri\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        sparql.setQuery(query)\n",
    "        for result in sparql.query().bindings:\n",
    "            so_pairs.append((result[\"output_s\"].value, result[\"output_obj\"].value, result[\"s\"].value, result[\"obj\"].value))\n",
    "    # sleep(1)\n",
    "    except (HTTPError, EndPointInternalError) as e:\n",
    "        print(f\"HTTPerror for uri {pred.uri}. Trying chained query.\")\n",
    "        so_pairs = get_so_pairs_for_pred_chained(pred)\n",
    "    finally:\n",
    "        time_elapsed = time.time() - start_time\n",
    "        print(f\"Time elapsed: {time_elapsed}\")\n",
    "        return so_pairs\n",
    "    \n",
    "def get_so_pairs_for_pred_chained(pred: Predicate) -> List[Tuple[str, str, str, str]]:\n",
    "    start_time = time.time()\n",
    "    print(f\"Querying {pred.uri} (chained).\")\n",
    "    so_pairs = []\n",
    "\n",
    "    query = \"\"\"\n",
    "SELECT DISTINCT ?s ?o WHERE {{\n",
    "    ?s <{}> ?o\n",
    "    BIND(MD5(CONCAT(STR(?s), STR(?o))) AS ?sortkey) .\n",
    "}}\n",
    "ORDER BY ?sortkey\n",
    "LIMIT 1000\n",
    "\"\"\".format(\n",
    "        pred.uri\n",
    "    )\n",
    "    \n",
    "    query_get_name_of_obj = \"\"\"\n",
    "SELECT DISTINCT ?output_obj WHERE {{\n",
    "    OPTIONAL {{\n",
    "      <{0}> rdfs:label ?obj_label . \n",
    "      FILTER (LANG(?obj_label) = 'en')\n",
    "    }} # Get the label (name) for the object if it exists\n",
    "    OPTIONAL {{\n",
    "      <{0}> rdf:type ?obj_type . \n",
    "      ?obj_type rdfs:label ?obj_type_name .\n",
    "      FILTER (LANG(?obj_type_name) = 'en')\n",
    "    }} # get the name of the type for the object if the type exists\n",
    "    BIND(COALESCE(IF(STR(?obj_label) != \"Generic instance\", ?obj_label, ?obj_type_name), <{0}>) AS ?output_obj) \n",
    "}}  \n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        sparql.setQuery(query)\n",
    "        for result in sparql.query().bindings:\n",
    "            # print(result)\n",
    "            s_uri = result[\"s\"].value\n",
    "            o_uri = result[\"o\"].value\n",
    "            query_s = query_get_name_of_obj.format(s_uri)            \n",
    "            sparql.setQuery(query_s)\n",
    "            res_s = sparql.query().bindings\n",
    "            if len(res_s) != 1:\n",
    "                raise ValueError(f\">1 label returned for subject {s_uri}: {res_s}\")\n",
    "            s_name = res_s[0][\"output_obj\"].value\n",
    "\n",
    "            query_obj = query_get_name_of_obj.format(o_uri)\n",
    "            sparql.setQuery(query_obj)\n",
    "            res_obj = sparql.query().bindings\n",
    "            if len(res_obj) != 1:\n",
    "                raise ValueError(f\">1 label returned for subject {o_uri}: {res_obj}\")\n",
    "            obj_name = res_obj[0][\"output_obj\"].value\n",
    "\n",
    "            so_pairs.append((s_name, obj_name, s_uri, o_uri))\n",
    "        \n",
    "    # sleep(1)\n",
    "    except (HTTPError, EndPointInternalError) as e:\n",
    "        print(f\"HTTPerror for uri {pred.uri} when chaining. Skipping.\")\n",
    "        so_pairs = None\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        time_elapsed = time.time() - start_time\n",
    "        print(f\"Time elapsed: {time_elapsed}\")\n",
    "        return so_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pred_uri_to_so_pairs from file ./yago_pred_uri_to_so_pairs_randomized_1k.json.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(PRED_URI_TO_SO_PAIRS_PATH):\n",
    "    print(f\"Loading pred_uri_to_so_pairs from file {PRED_URI_TO_SO_PAIRS_PATH}.\")\n",
    "    with open(PRED_URI_TO_SO_PAIRS_PATH) as f:\n",
    "        pred_uri_to_so_pairs = json.load(f)\n",
    "else:\n",
    "    pred_to_so_pairs: Dict[Predicate, List[Tuple[str, str, str, str]]] = {\n",
    "        pred: get_so_pairs_for_pred(pred) for pred in tqdm(relevant_preds)\n",
    "    }\n",
    "    pred_to_so_pairs = {k: v for k, v in pred_to_so_pairs.items() if v is not None}\n",
    "    pred_uri_to_so_pairs = {\n",
    "        k.uri: v for k, v in pred_to_so_pairs.items() if v is not None\n",
    "    }\n",
    "\n",
    "if TRY_QUERYING_MISSING_PREDS:\n",
    "    missing_preds = [p for p in relevant_preds if p.uri not in pred_uri_to_so_pairs]\n",
    "    print(\"Missing preds:\", missing_preds)\n",
    "    missing_pred_to_so_pairs: Dict[Predicate, List[Tuple[str, str, str, str]]] = {\n",
    "        pred: get_so_pairs_for_pred(pred) for pred in tqdm(missing_preds)\n",
    "    }\n",
    "    missing_pred_to_so_pairs = {k: v for k, v in missing_pred_to_so_pairs.items() if v is not None}\n",
    "    missing_pred_uri_to_so_pairs = {\n",
    "        k.uri: v for k, v in missing_pred_to_so_pairs.items() if v is not None\n",
    "    }\n",
    "\n",
    "    pred_uri_to_so_pairs = {**missing_pred_uri_to_so_pairs, **pred_uri_to_so_pairs}\n",
    "\n",
    "with open(PRED_URI_TO_SO_PAIRS_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(pred_uri_to_so_pairs, fp, ensure_ascii=False, indent=4)\n",
    "\n",
    "def augment_pred_uri_to_so_pairs_with_reverse(pred_uri_to_so_pairs):\n",
    "    return {\n",
    "        **pred_uri_to_so_pairs,\n",
    "        **{\n",
    "            f\"reverse-{k}\": [(a_label, e_label, a_uri, e_uri) for (e_label, a_label, e_uri, a_uri) in v]\n",
    "            for k, v in pred_uri_to_so_pairs.items()\n",
    "        },\n",
    "    }\n",
    "\n",
    "pred_uri_to_so_pairs_with_reverse = augment_pred_uri_to_so_pairs_with_reverse(\n",
    "    pred_uri_to_so_pairs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'http://schema.org/highestPoint', 'reverse-http://yago-knowledge.org/resource/capital', 'reverse-http://schema.org/actor', 'reverse-http://yago-knowledge.org/resource/appearsIn', 'http://yago-knowledge.org/resource/academicDegree', 'reverse-http://yago-knowledge.org/resource/notableWork', 'http://schema.org/gtin', 'http://yago-knowledge.org/resource/doctoralAdvisor', 'http://schema.org/lowestPoint', 'http://schema.org/postalCode', 'reverse-http://yago-knowledge.org/resource/replaces', 'http://schema.org/unemploymentRate', 'http://schema.org/worksFor', 'http://schema.org/neighbors', 'http://schema.org/birthDate', 'http://schema.org/award', 'http://schema.org/affiliation', 'http://schema.org/spouse', 'reverse-http://schema.org/musicBy', 'reverse-http://schema.org/editor', 'reverse-http://schema.org/sponsor', 'http://schema.org/editor', 'http://schema.org/numberOfPages', 'http://yago-knowledge.org/resource/replaces', 'http://schema.org/duns', 'http://schema.org/manufacturer', 'http://yago-knowledge.org/resource/beliefSystem', 'http://schema.org/administrates', 'http://schema.org/founder', 'http://schema.org/leader', 'http://yago-knowledge.org/resource/parallax', 'reverse-http://schema.org/homeLocation', 'http://schema.org/locationCreated', 'reverse-http://yago-knowledge.org/resource/conferredBy', 'http://yago-knowledge.org/resource/notableWork', 'http://schema.org/birthPlace', 'reverse-http://schema.org/officialLanguage', 'reverse-http://schema.org/leader', 'http://schema.org/ownedBy', 'http://yago-knowledge.org/resource/director', 'reverse-http://schema.org/author', 'http://yago-knowledge.org/resource/length', 'http://schema.org/inLanguage', 'reverse-http://yago-knowledge.org/resource/consumes', 'reverse-http://schema.org/director', 'http://schema.org/humanDevelopmentIndex', 'reverse-http://schema.org/ownedBy', 'http://schema.org/isbn', 'reverse-http://schema.org/founder', 'http://schema.org/director', 'http://schema.org/illustrator', 'http://schema.org/iswcCode', 'reverse-http://yago-knowledge.org/resource/flowsInto', 'http://schema.org/author', 'http://schema.org/homeLocation', 'http://yago-knowledge.org/resource/studentOf', 'http://schema.org/populationNumber', 'http://schema.org/knowsLanguage', 'http://schema.org/numberOfEmployees', 'http://schema.org/recordLabel', 'http://schema.org/alumniOf', 'http://schema.org/deathPlace', 'http://yago-knowledge.org/resource/distanceFromEarth', 'reverse-http://schema.org/owns', 'http://schema.org/url', 'reverse-http://schema.org/performer', 'http://schema.org/musicBy', 'http://schema.org/motto', 'http://schema.org/influencedBy', 'http://schema.org/sponsor', 'http://schema.org/address', 'http://schema.org/parentTaxon', 'reverse-http://schema.org/manufacturer', 'http://schema.org/children', 'http://yago-knowledge.org/resource/radialVelocity', 'http://schema.org/actor', 'http://schema.org/leiCode', 'reverse-http://yago-knowledge.org/resource/parentBody', 'reverse-http://schema.org/illustrator', 'reverse-http://schema.org/organizer', 'http://yago-knowledge.org/resource/participant', 'http://schema.org/startDate', 'http://schema.org/performer', 'http://yago-knowledge.org/resource/mass', 'http://schema.org/material', 'http://yago-knowledge.org/resource/consumes', 'http://schema.org/memberOf', 'http://yago-knowledge.org/resource/candidateIn', 'http://schema.org/elevation', 'reverse-http://yago-knowledge.org/resource/director', 'http://schema.org/iataCode', 'http://yago-knowledge.org/resource/playsIn', 'reverse-http://yago-knowledge.org/resource/doctoralAdvisor', 'http://yago-knowledge.org/resource/sportNumber', 'http://schema.org/officialLanguage', 'reverse-http://yago-knowledge.org/resource/playsIn', 'http://schema.org/deathDate', 'http://schema.org/numberOfEpisodes', 'http://schema.org/dissolutionDate', 'http://schema.org/organizer', 'http://yago-knowledge.org/resource/appearsIn', 'reverse-http://schema.org/worksFor', 'http://schema.org/nationality', 'http://schema.org/contentLocation', 'http://yago-knowledge.org/resource/parentBody', 'http://yago-knowledge.org/resource/capital', 'reverse-http://yago-knowledge.org/resource/participant', 'http://schema.org/dateCreated', 'http://schema.org/about', 'http://schema.org/numberOfSeasons', 'http://schema.org/endDate', 'http://schema.org/duration', 'reverse-http://schema.org/parentTaxon', 'reverse-http://schema.org/memberOf', 'http://yago-knowledge.org/resource/follows', 'http://yago-knowledge.org/resource/conferredBy', 'reverse-http://yago-knowledge.org/resource/studentOf', 'http://schema.org/icaoCode', 'reverse-http://schema.org/lyricist', 'http://yago-knowledge.org/resource/luminosity', 'http://yago-knowledge.org/resource/studentsCount', 'http://schema.org/demonym', 'http://yago-knowledge.org/resource/flowsInto', 'reverse-http://yago-knowledge.org/resource/terminus', 'http://schema.org/owns', 'http://yago-knowledge.org/resource/terminus', 'http://schema.org/lyricist'}\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "# 4. Construct queries containing entities, corresponding answers, query forms, and context templates. #\n",
    "########################################################################################################\n",
    "from yago_questions import yago_topic_to_qfs\n",
    "\n",
    "keys = set(yago_topic_to_qfs).intersection(set(pred_uri_to_so_pairs_with_reverse))\n",
    "print(keys)\n",
    "yago_qec = {\n",
    "    k: {\n",
    "        \"query_forms\": yago_topic_to_qfs[k],\n",
    "        \"entities\": list(zip(*pred_uri_to_so_pairs_with_reverse[k]))[0],\n",
    "        \"answers\": list(zip(*pred_uri_to_so_pairs_with_reverse[k]))[1],\n",
    "        \"entity_uris\": list(zip(*pred_uri_to_so_pairs_with_reverse[k]))[2],\n",
    "        \"answer_uris\": list(zip(*pred_uri_to_so_pairs_with_reverse[k]))[3],\n",
    "        \"context_templates\": [yago_topic_to_qfs[k][\"open\"][-1] + \" {answer}.\\n\"],\n",
    "        \"entity_types\": pred_to_s_and_obj_types_with_reverse[k][0], \n",
    "        \"answer_types\": pred_to_s_and_obj_types_with_reverse[k][1], \n",
    "    }\n",
    "    for k in keys\n",
    "}\n",
    "yago_qec\n",
    "with open(YAGO_QEC_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(yago_qec, fp, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(YAGO_QEC_PATH, \"r\") as fp:\n",
    "    yago_qec_reloaded = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://schema.org/highestPoint 1000 991\n",
      "reverse-http://yago-knowledge.org/resource/capital 1000 959\n",
      "reverse-http://schema.org/actor 1000 983\n",
      "reverse-http://yago-knowledge.org/resource/appearsIn 1000 727\n",
      "http://yago-knowledge.org/resource/academicDegree 1000 995\n",
      "reverse-http://yago-knowledge.org/resource/notableWork 1000 995\n",
      "http://schema.org/gtin 21 18\n",
      "http://yago-knowledge.org/resource/doctoralAdvisor 1000 949\n",
      "http://schema.org/lowestPoint 349 341\n",
      "http://schema.org/postalCode 1000 996\n",
      "reverse-http://yago-knowledge.org/resource/replaces 1000 980\n",
      "http://schema.org/unemploymentRate 195 133\n",
      "http://schema.org/worksFor 1000 998\n",
      "http://schema.org/neighbors 1000 998\n",
      "http://schema.org/birthDate 1000 999\n",
      "http://schema.org/award 1000 995\n",
      "http://schema.org/affiliation 1000 968\n",
      "http://schema.org/spouse 1000 999\n",
      "reverse-http://schema.org/musicBy 1000 777\n",
      "reverse-http://schema.org/editor 378 314\n",
      "reverse-http://schema.org/sponsor 780 352\n",
      "http://schema.org/editor 378 263\n",
      "http://schema.org/numberOfPages 224 224\n",
      "http://yago-knowledge.org/resource/replaces 1000 883\n",
      "http://schema.org/duns 119 119\n",
      "http://schema.org/manufacturer 1000 999\n",
      "http://yago-knowledge.org/resource/beliefSystem 1000 1000\n",
      "http://schema.org/administrates 1000 800\n",
      "http://schema.org/founder 1000 987\n",
      "http://schema.org/leader 1000 943\n",
      "http://yago-knowledge.org/resource/parallax 1000 998\n",
      "reverse-http://schema.org/homeLocation 1000 673\n",
      "http://schema.org/locationCreated 1000 997\n",
      "reverse-http://yago-knowledge.org/resource/conferredBy 1000 661\n",
      "http://yago-knowledge.org/resource/notableWork 1000 948\n",
      "http://schema.org/birthPlace 1000 1000\n",
      "reverse-http://schema.org/officialLanguage 438 188\n",
      "reverse-http://schema.org/leader 1000 962\n",
      "http://schema.org/ownedBy 1000 998\n",
      "http://yago-knowledge.org/resource/director 116 101\n",
      "reverse-http://schema.org/author 1000 910\n",
      "http://yago-knowledge.org/resource/length 1000 999\n",
      "http://schema.org/inLanguage 1000 996\n",
      "reverse-http://yago-knowledge.org/resource/consumes 202 112\n",
      "reverse-http://schema.org/director 1000 936\n",
      "http://schema.org/humanDevelopmentIndex 169 169\n",
      "reverse-http://schema.org/ownedBy 1000 657\n",
      "http://schema.org/isbn 570 570\n",
      "reverse-http://schema.org/founder 1000 986\n",
      "http://schema.org/director 1000 998\n",
      "http://schema.org/illustrator 226 216\n",
      "http://schema.org/iswcCode 1000 995\n",
      "reverse-http://yago-knowledge.org/resource/flowsInto 1000 811\n",
      "http://schema.org/author 1000 997\n",
      "http://schema.org/homeLocation 1000 995\n",
      "http://yago-knowledge.org/resource/studentOf 722 508\n",
      "http://schema.org/populationNumber 1000 995\n",
      "http://schema.org/knowsLanguage 1000 1000\n",
      "http://schema.org/numberOfEmployees 1000 960\n",
      "http://schema.org/recordLabel 165 163\n",
      "http://schema.org/alumniOf 1000 999\n",
      "http://schema.org/deathPlace 1000 1000\n",
      "http://yago-knowledge.org/resource/distanceFromEarth 1000 996\n",
      "reverse-http://schema.org/owns 1000 919\n",
      "http://schema.org/url 1000 1000\n",
      "reverse-http://schema.org/performer 1000 948\n",
      "http://schema.org/musicBy 1000 992\n",
      "http://schema.org/motto 1000 953\n",
      "http://schema.org/influencedBy 1000 841\n",
      "http://schema.org/sponsor 780 691\n",
      "http://schema.org/address 1000 997\n",
      "http://schema.org/parentTaxon 1000 1000\n",
      "reverse-http://schema.org/manufacturer 1000 684\n",
      "http://schema.org/children 1000 994\n",
      "http://yago-knowledge.org/resource/radialVelocity 1000 989\n",
      "http://schema.org/actor 1000 991\n",
      "http://schema.org/leiCode 1000 1000\n",
      "reverse-http://yago-knowledge.org/resource/parentBody 1000 572\n",
      "reverse-http://schema.org/illustrator 226 125\n",
      "reverse-http://schema.org/organizer 1000 282\n",
      "http://yago-knowledge.org/resource/participant 1000 853\n",
      "http://schema.org/startDate 1000 999\n",
      "http://schema.org/performer 1000 880\n",
      "http://yago-knowledge.org/resource/mass 1000 999\n",
      "http://schema.org/material 1000 954\n",
      "http://yago-knowledge.org/resource/consumes 202 89\n",
      "http://schema.org/memberOf 1000 999\n",
      "http://yago-knowledge.org/resource/candidateIn 1000 961\n",
      "http://schema.org/elevation 1000 998\n",
      "reverse-http://yago-knowledge.org/resource/director 116 110\n",
      "http://schema.org/iataCode 1000 994\n",
      "http://yago-knowledge.org/resource/playsIn 1000 992\n",
      "reverse-http://yago-knowledge.org/resource/doctoralAdvisor 1000 916\n",
      "http://yago-knowledge.org/resource/sportNumber 1000 999\n",
      "http://schema.org/officialLanguage 438 234\n",
      "reverse-http://yago-knowledge.org/resource/playsIn 1000 40\n",
      "http://schema.org/deathDate 1000 999\n",
      "http://schema.org/numberOfEpisodes 1000 996\n",
      "http://schema.org/dissolutionDate 1000 999\n",
      "http://schema.org/organizer 1000 1000\n",
      "http://yago-knowledge.org/resource/appearsIn 1000 917\n",
      "reverse-http://schema.org/worksFor 1000 631\n",
      "http://schema.org/nationality 1000 1000\n",
      "http://schema.org/contentLocation 1000 992\n",
      "http://yago-knowledge.org/resource/parentBody 1000 1000\n",
      "http://yago-knowledge.org/resource/capital 1000 986\n",
      "reverse-http://yago-knowledge.org/resource/participant 1000 914\n",
      "http://schema.org/dateCreated 1000 999\n",
      "http://schema.org/about 1000 989\n",
      "http://schema.org/numberOfSeasons 1000 996\n",
      "http://schema.org/endDate 1000 999\n",
      "http://schema.org/duration 1000 999\n",
      "reverse-http://schema.org/parentTaxon 1000 904\n",
      "reverse-http://schema.org/memberOf 1000 841\n",
      "http://yago-knowledge.org/resource/follows 1000 1000\n",
      "http://yago-knowledge.org/resource/conferredBy 1000 970\n",
      "reverse-http://yago-knowledge.org/resource/studentOf 722 653\n",
      "http://schema.org/icaoCode 1000 1000\n",
      "reverse-http://schema.org/lyricist 1000 746\n",
      "http://yago-knowledge.org/resource/luminosity 1000 1000\n",
      "http://yago-knowledge.org/resource/studentsCount 1000 980\n",
      "http://schema.org/demonym 1000 884\n",
      "http://yago-knowledge.org/resource/flowsInto 1000 985\n",
      "reverse-http://yago-knowledge.org/resource/terminus 1000 899\n",
      "http://schema.org/owns 1000 839\n",
      "http://yago-knowledge.org/resource/terminus 1000 926\n",
      "http://schema.org/lyricist 1000 960\n"
     ]
    }
   ],
   "source": [
    "for qid, v in yago_qec.items():\n",
    "    print(qid, len(v[\"entities\"]), len(set(v[\"entities\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.DataFrame(\n",
    "#     yago_qec[\"reverse-http://schema.org/homeLocation\"][\"entities\"]\n",
    "# ).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading entity_name_to_possible_entity_uris from file ./entity_name_to_possible_entity_uris.json.\n",
      "Loading entity_uri_to_degree from file ./entity_uri_to_degree.json.\n",
      "Loading entity_uri_to_degree_including_ambiguous_entities from file ./entity_uri_to_degree_including_ambiguous_entities.json.\n",
      "Loading entity_uri_to_predicate_degree from file ./entity_uri_to_predicate_degree_path.json.\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# 5. Get the degree of each entity #\n",
    "####################################\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "ENTITY_NAME_TO_POSSIBLE_ENTITY_URIS_PATH = os.path.join(DATA_ROOT, \"entity_name_to_possible_entity_uris.json\")\n",
    "ENTITY_URI_TO_DEGREE_PATH = os.path.join(DATA_ROOT, \"entity_uri_to_degree.json\")\n",
    "ENTITY_URI_TO_DEGREE_INCLUDING_AMBIGUOUS_ENTITIES_PATH = os.path.join(DATA_ROOT, \"entity_uri_to_degree_including_ambiguous_entities.json\")\n",
    "ENTITY_URI_TO_PREDICATE_DEGREE_PATH = os.path.join(DATA_ROOT, \"entity_uri_to_predicate_degree_path.json\")\n",
    "ENTITY_NAMESAKE_TO_DEGREE_PATH = os.path.join(DATA_ROOT, \"entity_namesake_to_degree.json\")\n",
    "ENTITY_NAMESAKE_TO_NUM_URIS_PATH = os.path.join(DATA_ROOT, \"entity_namesake_to_num_uris.json\")\n",
    "\n",
    "# Load cached jsons\n",
    "# {entity_name: List[entity_uri]}\n",
    "entity_name_to_possible_entity_uris: Dict[str, List[str]] = dict()\n",
    "if os.path.exists(ENTITY_NAME_TO_POSSIBLE_ENTITY_URIS_PATH):\n",
    "    print(f\"Loading entity_name_to_possible_entity_uris from file {ENTITY_NAME_TO_POSSIBLE_ENTITY_URIS_PATH}.\")\n",
    "    with open(ENTITY_NAME_TO_POSSIBLE_ENTITY_URIS_PATH) as f:\n",
    "        entity_name_to_possible_entity_uris = json.load(f)\n",
    "\n",
    "# {entity_uri: degree}\n",
    "entity_uri_to_degree: Dict[str, int] = dict()\n",
    "if os.path.exists(ENTITY_URI_TO_DEGREE_PATH):\n",
    "    print(f\"Loading entity_uri_to_degree from file {ENTITY_URI_TO_DEGREE_PATH}.\")\n",
    "    with open(ENTITY_URI_TO_DEGREE_PATH) as f:\n",
    "        entity_uri_to_degree = json.load(f)    \n",
    "\n",
    "# {entity_uri: degree}\n",
    "entity_uri_to_degree_including_ambiguous_entities: Dict[str, int] = dict()\n",
    "if os.path.exists(ENTITY_URI_TO_DEGREE_INCLUDING_AMBIGUOUS_ENTITIES_PATH):\n",
    "    print(f\"Loading entity_uri_to_degree_including_ambiguous_entities from file {ENTITY_URI_TO_DEGREE_INCLUDING_AMBIGUOUS_ENTITIES_PATH}.\")\n",
    "    with open(ENTITY_URI_TO_DEGREE_INCLUDING_AMBIGUOUS_ENTITIES_PATH) as f:\n",
    "        entity_uri_to_degree_including_ambiguous_entities = json.load(f)\n",
    "\n",
    "# {predicate: {entity: degree}}\n",
    "entity_uri_to_predicate_degree: Dict[str, Dict[str, int]] = defaultdict(dict) \n",
    "if os.path.exists(ENTITY_URI_TO_PREDICATE_DEGREE_PATH):\n",
    "    print(f\"Loading entity_uri_to_predicate_degree from file {ENTITY_URI_TO_PREDICATE_DEGREE_PATH}.\")\n",
    "    with open(ENTITY_URI_TO_PREDICATE_DEGREE_PATH) as f:\n",
    "        entity_uri_to_predicate_degree = defaultdict(dict, json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree_for_entity_uri(entity_uri: str) -> int:\n",
    "    start_time = time.time()\n",
    "    # print(f\"Querying degree of {entity_uri}.\")\n",
    "\n",
    "    query = \"\"\"\n",
    "SELECT (COUNT(?edge) as ?degree)\n",
    "WHERE {{\n",
    "  {{\n",
    "    <{0}> ?edge ?object.\n",
    "  }}\n",
    "  UNION\n",
    "  {{\n",
    "    ?subject ?edge <{0}>.\n",
    "  }}\n",
    "}}\n",
    "\"\"\".format(\n",
    "        entity_uri\n",
    "    )\n",
    "    try:\n",
    "        sparql.setQuery(query)\n",
    "        res_degree = sparql.query().bindings\n",
    "        if len(res_degree) != 1:\n",
    "            raise ValueError(f\">1 degree returned for entity {entity_uri}: {res_degree}\")\n",
    "        degree = res_degree[0][\"degree\"].value\n",
    "    # sleep(1)\n",
    "    except (HTTPError, EndPointInternalError) as e:\n",
    "        print(f\"HTTPerror for uri {entity_uri} when chaining. Skipping.\")\n",
    "        degree = None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        degree = None\n",
    "    finally:\n",
    "        time_elapsed = time.time() - start_time\n",
    "        # print(f\"Time elapsed: {time_elapsed}\")\n",
    "        return degree\n",
    "    \n",
    "def get_possible_entity_uris_per_entity(entity: str) -> int:\n",
    "    start_time = time.time()\n",
    "    # print(f\"Querying number of possible uris for entity {entity}.\")\n",
    "\n",
    "    query = \"\"\"\n",
    "SELECT ?entity_uri\n",
    "WHERE {{\n",
    "  ?entity_uri rdfs:label \"{}\"@en.\n",
    "}}\n",
    "\"\"\".format(\n",
    "        entity\n",
    "    )\n",
    "    # print(query)\n",
    "    entity_uris = []\n",
    "    try:\n",
    "        sparql.setQuery(query)\n",
    "        for result in sparql.query().bindings:\n",
    "            # print(result)\n",
    "            entity_uris.append(result[\"entity_uri\"].value)\n",
    "    # sleep(1)\n",
    "    except (HTTPError, EndPointInternalError) as e:\n",
    "        print(f\"HTTPerror for uri {entity}. Skipping.\")\n",
    "        entity_uris = None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        entity_uris = None\n",
    "    finally:\n",
    "        time_elapsed = time.time() - start_time\n",
    "        # print(f\"Time elapsed: {time_elapsed}\")\n",
    "        return entity_uris\n",
    "    \n",
    "def get_predicate_degree_for_entity_uri(entity_uri: str, predicate: str) -> int:\n",
    "    start_time = time.time()\n",
    "    # print(f\"Querying degree of {entity_uri}.\")\n",
    "\n",
    "    if predicate.startswith(\"reverse-\"):\n",
    "        predicate = predicate.split(\"reverse-\")[1]\n",
    "        query = \"\"\"\n",
    "                SELECT (COUNT(?subject) as ?degree) WHERE {{\n",
    "                    {{\n",
    "                        ?subject <{predicate}> <{entity_uri}>.\n",
    "                    }}\n",
    "                }}\n",
    "                \"\"\"\n",
    "    else:\n",
    "        query = \"\"\"\n",
    "                SELECT (COUNT(?object) as ?degree) WHERE {{\n",
    "                    {{\n",
    "                        <{entity_uri}> <{predicate}> ?object.\n",
    "                    }}\n",
    "                }}\n",
    "                \"\"\"\n",
    "        \n",
    "    query = query.format(\n",
    "        entity_uri=entity_uri,\n",
    "        predicate=predicate\n",
    "    )\n",
    "    # print(query)\n",
    "    try:\n",
    "        sparql.setQuery(query)\n",
    "        res_degree = sparql.query().bindings\n",
    "        if len(res_degree) != 1:\n",
    "            raise ValueError(f\">1 degree returned for entity {entity_uri}: {res_degree}\")\n",
    "        degree = res_degree[0][\"degree\"].value\n",
    "    # sleep(1)\n",
    "    except (HTTPError, EndPointInternalError) as e:\n",
    "        print(f\"HTTPerror for uri {entity_uri} when chaining. Skipping.\")\n",
    "        degree = None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        degree = None\n",
    "    finally:\n",
    "        time_elapsed = time.time() - start_time\n",
    "        # print(f\"Time elapsed: {time_elapsed}\")\n",
    "        return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96271, 95030, 112536, 78946)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the relevant list of entity uris and entity names.\n",
    "entity_uris: List[str] = list(set(itertools.chain.from_iterable([v[\"entity_uris\"] for _, v in yago_qec.items()])))\n",
    "entities: List[str] = list(set(itertools.chain.from_iterable([v[\"entities\"] for _, v in yago_qec.items()])))\n",
    "predicate_to_entity_uris: Dict[str, List[str]] = {predicate: qec[\"entity_uris\"] for predicate, qec in yago_qec.items()}\n",
    "answers: List[str] = list(set(itertools.chain.from_iterable([v[\"answers\"] for _, v in yago_qec.items()])))\n",
    "\n",
    "# # Test run examples\n",
    "# entity_uris = [\"http://yago-knowledge.org/resource/Paul_McCartney\", \"http://yago-knowledge.org/resource/Paul_Allen__u0028_editor_u0029_\"]\n",
    "# entities = [\"Paul McCartney\", \"Paul Allen\"]\n",
    "# predicate_to_entity_uris = defaultdict(\n",
    "#     dict,\n",
    "#     {\n",
    "#         \"reverse-http://schema.org/author\": [\"http://yago-knowledge.org/resource/Anton_Chekhov\", \"http://yago-knowledge.org/resource/Alexander_Hamilton\"],\n",
    "#         \"http://schema.org/author\": [\"http://yago-knowledge.org/resource/A_Marriage_Proposal\"],\n",
    "#     }\n",
    "# )\n",
    "len(entity_uris), len(entities), sum(len(v) for v in predicate_to_entity_uris.values()), len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITIES_PATH = os.path.join(DATA_ROOT, \"entities.json\")\n",
    "ANSWERS_PATH = os.path.join(DATA_ROOT, \"answers.json\")\n",
    "\n",
    "with open(ENTITIES_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(entities, fp, ensure_ascii=False, indent=4)\n",
    "    \n",
    "with open(ANSWERS_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(answers, fp, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 95030, 95031)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_entities = set(entities).difference(set(entity_name_to_possible_entity_uris))\n",
    "len(missing_entities), len(set(entities)), len(set(entity_name_to_possible_entity_uris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 96271, 96272)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_entity_uris = set(entity_uris).difference(set(entity_uri_to_degree))\n",
    "len(missing_entity_uris), len(set(entity_uris)), len(set(entity_uri_to_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 127/127 [00:00<00:00, 6026.09it/s]\n",
      "100%|██████████| 127/127 [00:00<00:00, 42937.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95031, 96272, 169229, 127)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the jsons mapping (a) from entity names to uris, (b) from entity uris to degrees, and (c) from entity uris (including those of the namesake) to degrees\n",
    "# This will additively build from the cached files.\n",
    "missing_entities = set(entities).difference(set(entity_name_to_possible_entity_uris))\n",
    "entity_name_to_possible_entity_uris = {\n",
    "    **entity_name_to_possible_entity_uris, \n",
    "    **{\n",
    "        entity: get_possible_entity_uris_per_entity(entity) for entity in tqdm(missing_entities)\n",
    "    }\n",
    "}\n",
    "with open(ENTITY_NAME_TO_POSSIBLE_ENTITY_URIS_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(entity_name_to_possible_entity_uris, fp, ensure_ascii=False, indent=4)\n",
    "\n",
    "missing_entity_uris = set(entity_uris).difference(set(entity_uri_to_degree))\n",
    "entity_uri_to_degree = {\n",
    "    **entity_uri_to_degree,\n",
    "    **{entity_uri: get_degree_for_entity_uri(entity_uri) for entity_uri in tqdm(missing_entity_uris)}\n",
    "}\n",
    "with open(ENTITY_URI_TO_DEGREE_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(entity_uri_to_degree, fp, ensure_ascii=False, indent=4)\n",
    "\n",
    "missing_entity_uris_ambiguous = {entity_uri for entity in entities for entity_uri in entity_name_to_possible_entity_uris[entity]}.difference(set(entity_uri_to_degree_including_ambiguous_entities))\n",
    "entity_uri_to_degree_including_ambiguous_entities = {\n",
    "    **entity_uri_to_degree_including_ambiguous_entities,\n",
    "    **{\n",
    "        entity_uri: get_degree_for_entity_uri(entity_uri) if entity_uri not in entity_uri_to_degree else entity_uri_to_degree[entity_uri] for entity_uri in missing_entity_uris_ambiguous\n",
    "    },\n",
    "}\n",
    "with open(ENTITY_URI_TO_DEGREE_INCLUDING_AMBIGUOUS_ENTITIES_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(entity_uri_to_degree_including_ambiguous_entities, fp, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "missing_entity_predicate_uris = defaultdict(\n",
    "    dict, \n",
    "    {\n",
    "        predicate: {\n",
    "            entity_uri for entity_uri in set(predicate_to_entity_uris[predicate]).difference(set(entity_uri_to_predicate_degree[predicate]))\n",
    "        } for predicate in tqdm(yago_qec_reloaded)\n",
    "    }\n",
    ")\n",
    "entity_uri_to_predicate_degree = {\n",
    "    predicate: {\n",
    "        **entity_uri_to_predicate_degree[predicate],\n",
    "        **{\n",
    "            entity_uri: get_predicate_degree_for_entity_uri(entity_uri, predicate) for entity_uri in missing_entity_predicate_uris[predicate]\n",
    "        } \n",
    "    } for predicate in tqdm(yago_qec_reloaded)\n",
    "}\n",
    "with open(ENTITY_URI_TO_PREDICATE_DEGREE_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(entity_uri_to_predicate_degree, fp, ensure_ascii=False, indent=4)    \n",
    "\n",
    "len(entity_name_to_possible_entity_uris), len(entity_uri_to_degree), len(entity_uri_to_degree_including_ambiguous_entities), len(entity_uri_to_predicate_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95031, 96272, 169229, 127)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_name_to_possible_entity_uris), len(entity_uri_to_degree), len(entity_uri_to_degree_including_ambiguous_entities), len(entity_uri_to_predicate_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct and save entity_namesake_to_* jsons.\n",
    "# {entity_namesake: degree}\n",
    "entity_namesake_to_degree: Dict[str, int] = {\n",
    "    k: sum([int(entity_uri_to_degree_including_ambiguous_entities[uri]) for uri in uris]) for k, uris in entity_name_to_possible_entity_uris.items()\n",
    "}\n",
    "with open(ENTITY_NAMESAKE_TO_DEGREE_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(entity_namesake_to_degree, fp, ensure_ascii=False, indent=4)\n",
    "\n",
    "# {entity_namesake: number of uris with that name}\n",
    "entity_namesake_to_num_uris: Dict[str, int] = {\n",
    "    k: len(uris) for k, uris in entity_name_to_possible_entity_uris.items()\n",
    "}\n",
    "with open(ENTITY_NAMESAKE_TO_NUM_URIS_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(entity_namesake_to_num_uris, fp, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://schema.org/lyricist',\n",
       " [(7, 'A Porter’s Love Song to a Chambermaid'),\n",
       "  (7, 'Go, Mississippi'),\n",
       "  (8, 'Forbidden Broadway Goes to Rehab'),\n",
       "  (8, 'First Daughter Suite'),\n",
       "  (8, 'Darlinghurst Nights'),\n",
       "  (8, 'A Day in Hollywood / A Night in the Ukraine'),\n",
       "  (9, 'The Night That Made America Famous'),\n",
       "  (9, 'Beautiful and Damned'),\n",
       "  (9, 'I and Albert'),\n",
       "  (9, 'Ude Dil Befikre')])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incorporate above entity_namesake_to_* and entity_uri_to_* stats into yago_qec\n",
    "\n",
    "# Load yago entity namesake to degree stats (including all entity uris sharing that namesake)\n",
    "ENTITY_NAMESAKE_TO_DEGREE_PATH = os.path.join(DATA_ROOT, \"entity_namesake_to_degree.json\")\n",
    "with open(ENTITY_NAMESAKE_TO_DEGREE_PATH, \"r\") as fp:\n",
    "    entity_namesake_to_degree = json.load(fp)\n",
    "    \n",
    "for k, v in yago_qec.items():\n",
    "    yago_qec[k][\"entity_namesake_to_degree\"] = [\n",
    "        int(entity_namesake_to_degree[entity]) for entity in yago_qec[k][\"entities\"]\n",
    "    ]\n",
    "    \n",
    "# Save yago_qec including fake entities\n",
    "with open(YAGO_QEC_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(yago_qec, fp, ensure_ascii=False, indent=4)\n",
    "\n",
    "k, sorted(list(zip(yago_qec[k][\"entity_namesake_to_degree\"], yago_qec[k][\"entities\"])), key=lambda x: x[0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://schema.org/lyricist',\n",
       " [(231, 'Selah'),\n",
       "  (231, 'Selah'),\n",
       "  (240, \"I'm Beginning to See the Light\"),\n",
       "  (240, \"I'm Beginning to See the Light\"),\n",
       "  (252, 'Kings & Queens'),\n",
       "  (255, 'Il Canto degli Italiani'),\n",
       "  (260, 'High Hopes'),\n",
       "  (262, 'Blue Monday'),\n",
       "  (279, 'God Save the Queen'),\n",
       "  (283, 'The Internationale')])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load yago entity uri to degree stats\n",
    "ENTITY_URI_TO_DEGREE_PATH = os.path.join(DATA_ROOT, \"entity_uri_to_degree.json\")\n",
    "with open(ENTITY_URI_TO_DEGREE_PATH, \"r\") as fp:\n",
    "    entity_uri_to_degree = json.load(fp)\n",
    "    \n",
    "for k, v in yago_qec.items():\n",
    "    yago_qec[k][\"entity_uri_to_degree\"] = [\n",
    "        int(entity_uri_to_degree[uri]) for uri in yago_qec[k][\"entity_uris\"]\n",
    "    ]\n",
    "    \n",
    "# Save yago_qec including fake entities\n",
    "with open(YAGO_QEC_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(yago_qec, fp, ensure_ascii=False, indent=4)\n",
    "\n",
    "k, sorted(list(zip(yago_qec[k][\"entity_uri_to_degree\"], yago_qec[k][\"entities\"])), key=lambda x: x[0])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://schema.org/lyricist',\n",
       " [(43, 'The Gift'),\n",
       "  (43, 'Alone'),\n",
       "  (46, 'Tonight'),\n",
       "  (50, 'You'),\n",
       "  (50, 'Destiny'),\n",
       "  (51, 'Friends'),\n",
       "  (61, 'Hero'),\n",
       "  (72, 'Angel'),\n",
       "  (72, 'Angel'),\n",
       "  (74, 'Symphony No. 2')])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load yago entity namesake to number of different uris\n",
    "ENTITY_NAMESAKE_TO_NUM_URIS_PATH = os.path.join(DATA_ROOT, \"entity_namesake_to_num_uris.json\")\n",
    "with open(ENTITY_NAMESAKE_TO_NUM_URIS_PATH, \"r\") as fp:\n",
    "    entity_namesake_to_num_uris = json.load(fp)\n",
    "    \n",
    "for k, v in yago_qec.items():\n",
    "    yago_qec[k][\"entity_namesake_to_num_uris\"] = [\n",
    "        int(entity_namesake_to_num_uris[entity]) for entity in yago_qec[k][\"entities\"]\n",
    "    ]\n",
    "    \n",
    "# Save yago_qec including fake entities\n",
    "with open(YAGO_QEC_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(yago_qec, fp, ensure_ascii=False, indent=4)\n",
    "\n",
    "k, sorted(list(zip(yago_qec[k][\"entity_namesake_to_num_uris\"], yago_qec[k][\"entities\"])), key=lambda x: x[0])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://schema.org/lyricist',\n",
       " [(7, 'Greatest'),\n",
       "  (7, 'Creep'),\n",
       "  (7, \"John Murray Anderson's Almanac\"),\n",
       "  (8, 'Nocturne'),\n",
       "  (9, 'So Appalled'),\n",
       "  (9, 'Selah'),\n",
       "  (9, 'High Hopes'),\n",
       "  (9, 'Selah'),\n",
       "  (12, 'On the Record'),\n",
       "  (12, 'On the Record')])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load yago entity namesake to number of different uris\n",
    "with open(ENTITY_URI_TO_PREDICATE_DEGREE_PATH, \"r\") as fp:\n",
    "    entity_uri_to_predicate_degree = json.load(fp)\n",
    "    \n",
    "for k, v in yago_qec.items():\n",
    "    yago_qec[k][\"entity_uri_to_predicate_degree\"] = [\n",
    "        int(entity_uri_to_predicate_degree[k][uri]) for uri in yago_qec[k][\"entity_uris\"]\n",
    "    ]\n",
    "    \n",
    "# Save yago_qec including fake entities\n",
    "with open(YAGO_QEC_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(yago_qec, fp, ensure_ascii=False, indent=4)\n",
    "\n",
    "k, sorted(list(zip(yago_qec[k][\"entity_uri_to_predicate_degree\"], yago_qec[k][\"entities\"])), key=lambda x: x[0])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predicate_to_entity_uris[\"reverse-http://schema.org/organizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################\n",
    "# # 5. Construct fake entities #\n",
    "# ##############################\n",
    "# # This section requires GPUs #\n",
    "# ##############################\n",
    "\n",
    "# # Can be run separate from previous section #\n",
    "# from transformers import ReformerModelWithLMHead\n",
    "# import json\n",
    "# import re\n",
    "# import os\n",
    "# import itertools\n",
    "# from transformers import ReformerModelWithLMHead\n",
    "\n",
    "# import torch\n",
    "# import random\n",
    "# import numpy as np\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Encoding\n",
    "# def encode(list_of_strings, pad_token_id=0, device=\"cpu\"):\n",
    "#     max_length = max([len(string) for string in list_of_strings])\n",
    "\n",
    "#     # create emtpy tensors\n",
    "#     attention_masks = torch.zeros((len(list_of_strings), max_length), dtype=torch.long)\n",
    "#     input_ids = torch.full((len(list_of_strings), max_length), pad_token_id, dtype=torch.long)\n",
    "\n",
    "#     for idx, string in enumerate(list_of_strings):\n",
    "#         # make sure string is in byte format\n",
    "#         if not isinstance(string, bytes):\n",
    "#             string = str.encode(string)\n",
    "\n",
    "#         input_ids[idx, :len(string)] = torch.tensor([x + 2 for x in string])\n",
    "#         attention_masks[idx, :len(string)] = 1\n",
    "\n",
    "#     return input_ids.to(device), attention_masks.to(device)\n",
    "    \n",
    "# # Decoding\n",
    "# def decode(outputs_ids):\n",
    "#     decoded_outputs = []\n",
    "#     for output_ids in outputs_ids.tolist():\n",
    "#         # transform id back to char IDs < 2 are simply transformed to \"\"\n",
    "#         decoded_outputs.append(\"\".join([chr(x - 2) if x > 1 else \"\" for x in output_ids]))\n",
    "#     return decoded_outputs\n",
    "\n",
    "# def set_seed(seed=0):\n",
    "#     torch.manual_seed(seed)\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "    \n",
    "# def extract_entity(text):\n",
    "#     regex_pattern = r'\\[\\[([^\\[|\\]]+?)(?:\\([^)]*\\))?(?:\\|[^|\\]]+)*\\]\\]'\n",
    "#     match = re.search(regex_pattern, text)\n",
    "\n",
    "#     if match:\n",
    "#         result = match.group(1).strip()\n",
    "#         return result\n",
    "    \n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# from typing import Dict, Set\n",
    "\n",
    "# with open(YAGO_QEC_PATH, \"r\") as fp:\n",
    "#     yago_qec = json.load(fp)\n",
    "# entity_types_to_real_entities: Dict[str, Set[str]] = defaultdict(set)\n",
    "# for query_id, qec in yago_qec.items():\n",
    "#     for et in qec[\"entity_types\"]:\n",
    "#         entity_types_to_real_entities[et] = entity_types_to_real_entities[et].union(qec[\"entities\"])\n",
    "# print(json.dumps({k: len(v) for k, v in entity_types_to_real_entities.items()}, indent=4))\n",
    "\n",
    "# real_entities = set(itertools.chain.from_iterable([v[\"entities\"] for _, v in yago_qec.items()]))\n",
    "# print(len(real_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity_types_to_prompts = {\n",
    "#     \"http://schema.org/CreativeWork\": \"The creative work called [[\",\n",
    "#     \"http://schema.org/Event\": \"The event called [[\",\n",
    "#     \"http://schema.org/Intangible\": \"The concept called [[\",\n",
    "#     \"http://schema.org/Organization\": \"The organization is called [[\",\n",
    "#     \"http://schema.org/Person\": \"The person named [[\",\n",
    "#     \"http://schema.org/Place\": \"The place is named [[\",\n",
    "#     \"http://schema.org/Product\": \"The product is called [[\",\n",
    "#     \"http://schema.org/Taxon\": \"The taxon named [[\",\n",
    "#     \"http://schema.org/FictionalEntity\": \"The fictional entity named [[\",\n",
    "# }\n",
    "# entity_types_to_fake_entities = {}\n",
    "# model = ReformerModelWithLMHead.from_pretrained(\"google/reformer-enwik8\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for et, p in entity_types_to_prompts.items():\n",
    "#     set_seed(0)\n",
    "#     print(f\"***{et}***\")\n",
    "#     encoded, attention_masks = encode([p], device=device)\n",
    "#     res = decode(model.generate(encoded, do_sample=True, num_return_sequences=1200, max_length=100))\n",
    "\n",
    "#     extracted_res = {extract_entity(s) for s in res if extract_entity(s) is not None}\n",
    "#     print(f\"# unique fake ents: {len(extracted_res)}\")\n",
    "#     extracted_res_without_reals = extracted_res.difference(real_entities)\n",
    "#     print(f\"# unique fake ents removing reals: {len(extracted_res_without_reals)}\")\n",
    "#     extracted_res = random.sample(list(extracted_res), 1000)\n",
    "#     entity_types_to_fake_entities[et] = extracted_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAGO_FAKE_ENTITIES_PATH = os.path.join(DATA_ROOT, \"fake_entities.json\") \n",
    "\n",
    "# # Load yago_qec\n",
    "# with open(YAGO_QEC_PATH, \"r\") as fp:\n",
    "#     yago_qec = json.load(fp)\n",
    "\n",
    "# # Save fake entities per each entity type.\n",
    "# with open(YAGO_FAKE_ENTITIES_PATH, \"w\", encoding='utf-8') as fp:\n",
    "#     json.dump(entity_types_to_fake_entities, fp, ensure_ascii=False, indent=4)\n",
    "\n",
    "# # Randomly sample fake entities that are eligible according to entity type for each relation and save to yago_qec\n",
    "# for k, v in yago_qec.items():\n",
    "#     entity_types = yago_qec[k][\"entity_types\"]\n",
    "#     eligible_fake_entities = list(itertools.chain.from_iterable([entity_types_to_fake_entities[et] for et in entity_types]))\n",
    "#     yago_qec[k][\"fake_entities\"] = random.sample(eligible_fake_entities, len(yago_qec[k][\"entities\"]))\n",
    "\n",
    "# # Save yago_qec including fake entities\n",
    "# with open(YAGO_QEC_PATH, \"w\", encoding='utf-8') as fp:\n",
    "#     json.dump(yago_qec, fp, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# 6. Construct fake entities with chatgpt #\n",
    "###########################################\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed(0)\n",
    "YAGO_GPT_FAKE_ENTITIES_PATH = os.path.join(DATA_ROOT, \"chatgpt_fake_entities_all.csv\") \n",
    "\n",
    "fake_entities_gpt_df = pd.read_csv(YAGO_GPT_FAKE_ENTITIES_PATH)\n",
    "fake_entities_gpt_df = fake_entities_gpt_df.add_prefix(\"http://schema.org/\")\n",
    "\n",
    "# Load yago_qec\n",
    "with open(YAGO_QEC_PATH, \"r\") as fp:\n",
    "    yago_qec = json.load(fp)\n",
    "\n",
    "# Randomly sample fake entities that are eligible according to entity type for each relation and save to yago_qec\n",
    "for k, v in yago_qec.items():\n",
    "    entity_types = yago_qec[k][\"entity_types\"]\n",
    "    if set(entity_types).issubset(set(fake_entities_gpt_df.columns)):\n",
    "        eligible_fake_entities = list(itertools.chain.from_iterable([fake_entities_gpt_df[et] for et in entity_types]))\n",
    "        yago_qec[k][\"gpt_fake_entities\"] = random.sample(eligible_fake_entities, min(len(yago_qec[k][\"entities\"]), len(eligible_fake_entities)))\n",
    "\n",
    "yago_qec = {k: v for k, v in yago_qec.items() if \"gpt_fake_entities\" in v}\n",
    "\n",
    "# Save yago_qec including fake entities\n",
    "with open(YAGO_QEC_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(yago_qec, fp, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of all gpt fake entities\n",
    "import pandas as pd\n",
    "YAGO_GPT_FAKE_ENTITIES_PATH = os.path.join(DATA_ROOT, \"chatgpt_fake_entities_all.csv\") \n",
    "YAGO_GPT_FAKE_ENTITIES_LIST_PATH = os.path.join(DATA_ROOT, \"chatgpt_fake_entities_list.json\") \n",
    "fake_entities_gpt_df = pd.read_csv(YAGO_GPT_FAKE_ENTITIES_PATH)\n",
    "fake_entities = fake_entities_gpt_df.values.ravel().tolist()\n",
    "# Save yago_qec including fake entities\n",
    "with open(YAGO_GPT_FAKE_ENTITIES_LIST_PATH, \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(fake_entities, fp, ensure_ascii=False, indent=4)\n",
    "len(set(fake_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yago_qec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'http://yago-knowledge.org/resource/conferredBy',\n",
       " 'reverse-http://schema.org/officialLanguage'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k for k, v in yago_qec.items() if \"http://schema.org/Intangible\" in v[\"entity_types\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load yago_qec\n",
    "with open(\"yago_qec.json\", \"r\") as fp:\n",
    "    yago_qec = json.load(fp)\n",
    "\n",
    "df = pd.read_csv(\"../CountryCapital/real-fake-historical-country-capital.csv\")\n",
    "countries = df[df[\"type\"] == \"countryCapital\"][\"country\"].tolist()\n",
    "capitals = df[df[\"type\"] == \"countryCapital\"][\"capital\"].tolist()\n",
    "my_fake_countries = df[df[\"type\"] == \"fakeCountryCapital\"][\"country\"].tolist()\n",
    "my_fake_capitals = df[df[\"type\"] == \"fakeCountryCapital\"][\"capital\"].tolist()\n",
    "\n",
    "yago_qec[\"http://yago-knowledge.org/resource/capital\"][\"my_famous_entities\"] = countries\n",
    "# yago_qec[\"http://yago-knowledge.org/resource/capital\"][\"famous_answers\"] = capitals\n",
    "yago_qec[\"http://yago-knowledge.org/resource/capital\"][\"my_fake_entities\"] = my_fake_countries\n",
    "# yago_qec[\"http://yago-knowledge.org/resource/capital\"][\"my_fake_answers\"] = my_fake_capitals\n",
    "\n",
    "# Save yago_qec including fake entities\n",
    "with open(\"yago_qec.json\", \"w\", encoding='utf-8') as fp:\n",
    "    json.dump(yago_qec, fp, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
