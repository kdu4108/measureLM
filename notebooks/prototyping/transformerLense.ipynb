{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c80174",
   "metadata": {},
   "source": [
    "# TransformerLense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1021f557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-medium into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import transformer_lens\n",
    "\n",
    "# Load a model (eg GPT-2 Small)\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\"gpt2-medium\")\n",
    "model.tokenizer.pad_token = model.tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e51a2010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float, Int\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "552d88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model and get logits and activations\n",
    "tokens = model.to_tokens(\"Hello World\")\n",
    "logits, activs = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c4739667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.15.hook_mlp_out\n",
      "\n",
      "\n",
      "tensor([[ 8.6360,  5.9398,  5.7453,  ..., -6.0667, -4.5309,  9.9179]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>)\n",
      "blocks.16.hook_mlp_out\n",
      "\n",
      "\n",
      "tensor([[ 8.3343,  5.7695,  5.0471,  ..., -5.8012, -4.0417, 10.2291]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>)\n",
      "blocks.17.hook_mlp_out\n",
      "\n",
      "\n",
      "tensor([[ 8.6266,  5.8475,  5.3887,  ..., -5.5492, -4.3809, 10.1597]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def mlp_out_hook(mlp_out_new, hook: HookPoint, old_activs: torch.Tensor, token_idx:int): \n",
    "    print(f'{hook.name}')\n",
    "    mlp_out_old = old_activs[hook.name]\n",
    "    mlp_out_new[:, token_idx, :] = mlp_out_old[:, token_idx, :]\n",
    "    print(\"\\n\")\n",
    "    return mlp_out_new\n",
    "\n",
    "\n",
    "def intervene(new_prompt, old_activs, tok_idx = -1, l_start_end=[0, 99]):\n",
    "    for layer in range(l_start_end[0], l_start_end[1]):\n",
    "        if layer < model.cfg.n_layers:\n",
    "            temp_hook_fn = partial(mlp_out_hook, old_activs=old_activs, token_idx=tok_idx)            \n",
    "            patched_scores = model.run_with_hooks(new_tokens, fwd_hooks=[(utils.get_act_name(\"mlp_out\", layer), temp_hook_fn)])\n",
    "            print(patched_scores[:,tok_idx,:])\n",
    "\n",
    "new_prompt = \"This is great right?\"\n",
    "new_tokens = model.to_tokens(new_prompt)\n",
    "\n",
    "intervene(new_tokens, activs, tok_idx = -1, l_start_end=[15, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c6c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "measureLM_venv",
   "language": "python",
   "name": "measurelm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
