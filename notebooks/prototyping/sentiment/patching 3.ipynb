{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce2fcce",
   "metadata": {},
   "source": [
    "## Activation Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb7ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, transformer_lens, itertools\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from measureLM import visualizing, decoding, patching, scoring\n",
    "\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_heatmap(array, title='', cmap=\"binary\"):\n",
    "    titlefont, labelsize=12, 10\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2, 4), gridspec_kw={'hspace': 0.4})\n",
    "    ax = sns.heatmap(array, cmap=mpl.colormaps[cmap], xticklabels=hook_names, square=False)\n",
    "    ax.set_title(title, fontsize=titlefont, color=\"black\", loc='center')\n",
    "    ax.set_ylabel('layers', fontsize=labelsize)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c2959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-medium into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "model = transformer_lens.HookedTransformer.from_pretrained(\"gpt2-medium\").to(\"cpu\")\n",
    "model.cfg.spacing = \"Ä \"\n",
    "model.tokenizer.pad_token = model.tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8060b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_logits(logits, token_list=[\"friendly\", \"hostile\"]): #[\"positive\", \"negative\"], [\"friendly\", \"hostile\"]\n",
    "    indices = torch.LongTensor([model.tokenizer.encode(f\" {token}\")[0] for token in token_list])\n",
    "    logits = torch.index_select(logits, -1, indices)\n",
    "    logits_v = logits / logits.sum()\n",
    "    return logits_v[0].item() ## toDo: remove this later!\n",
    "\n",
    "\n",
    "def get_vector_dist(vec_a, vec_b, norm=True):\n",
    "    pdist = torch.nn.PairwiseDistance(p=2)\n",
    "    if norm:\n",
    "        vec_a = torch.nn.functional.normalize(vec_a, p=2.0, dim=-1)\n",
    "        vec_b = torch.nn.functional.normalize(vec_b, p=2.0, dim=-1)\n",
    "    vec_dist = pdist(vec_a, vec_b)\n",
    "    return vec_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ffac95",
   "metadata": {},
   "source": [
    "## Check change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89a0cc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5680946707725525 0.48172956705093384\n"
     ]
    }
   ],
   "source": [
    "prompt = [\"The relationship between Harry Potter and Ronald Weasley is\"]\n",
    "corrupt_prompt = [\"The relationship between Mikel Black and Wesley Smith is\"]\n",
    "\n",
    "prompt = [\"The relationship between Harry Potter and Ronald Weasley is\"]\n",
    "corrupt_prompt = [\"Harry absolutely hates Ron. The relationship between Harry Potter and Ronald Weasley is\"]\n",
    "\n",
    "#prompt = [\"The relationship between Biden and Trump is\"]\n",
    "#corrupt_prompt = [\"Biden loves Trump. The relationship between Biden and Trump is\"]\n",
    "\n",
    "\n",
    "logits, activs = model.run_with_cache(prompt)\n",
    "corrupt_logits, corrupt_activs = model.run_with_cache(corrupt_prompt)\n",
    "\n",
    "logits_v = select_logits(logits[0,-1])\n",
    "corrupt_logits_v = select_logits(corrupt_logits[0,-1])\n",
    "\n",
    "print(logits_v, corrupt_logits_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13a20f",
   "metadata": {},
   "source": [
    "## Find Mechanistic Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c532f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_hook_point(patched_activs, hook: HookPoint, old_activs, hook_layer_name, extract_tok_idx=-1, insert_tok_idx=None):\n",
    "    #print(f'patching {hook.name} <-- {hook_layer_name}')\n",
    "    if extract_tok_idx is None or extract_tok_idx == -1:\n",
    "        extract_tok_idx = (0, -1)\n",
    "    if insert_tok_idx is None:\n",
    "        insert_tok_idx = extract_tok_idx\n",
    "    old_activs_hook = old_activs[hook_layer_name]\n",
    "    patched_activs[insert_tok_idx] = old_activs_hook[extract_tok_idx]\n",
    "    return patched_activs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0617afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5680946707725525 0.5479690432548523\n"
     ]
    }
   ],
   "source": [
    "n_layers = model.cfg.n_layers\n",
    "        \n",
    "hook_layer_name = transformer_lens.utils.get_act_name(\"attn_out\", 17) #attn_out, mlp_out\n",
    "patch_layers_fn = [(hook_layer_name, partial(patch_hook_point, old_activs=corrupt_activs, hook_layer_name=hook_layer_name))]\n",
    "corrupt_logits = model.run_with_hooks(prompt,fwd_hooks=patch_layers_fn,reset_hooks_end=True)\n",
    "\n",
    "logits_v = select_logits(logits[0,-1])\n",
    "corrupt_logits_v = select_logits(corrupt_logits[0,-1])             \n",
    "print(logits_v, corrupt_logits_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0ed96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "measureLM_venv",
   "language": "python",
   "name": "measurelm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
