{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce2fcce",
   "metadata": {},
   "source": [
    "# Activation Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb7ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, transformer_lens, itertools\n",
    "from functools import partial\n",
    "\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from measureLM import helpers, measuring, synth_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677eebb1",
   "metadata": {},
   "source": [
    "## Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ddab8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 50.06 GB, other allocations: 31.39 GB, max allowed: 81.60 GB). Tried to allocate 196.32 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2-medium\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmeasuring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM/measuring.py:4\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_name, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2-small\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_lens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHookedTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mspacing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÄ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/transformer_lens/HookedTransformer.py:945\u001b[0m, in \u001b[0;36mHookedTransformer.from_pretrained\u001b[0;34m(cls, model_name, fold_ln, center_writing_weights, center_unembed, refactor_factored_attn_matrices, checkpoint_index, checkpoint_value, hf_model, device, n_devices, tokenizer, move_to_device, fold_value_biases, default_prepend_bos, **from_pretrained_kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m model\u001b[38;5;241m.\u001b[39mload_and_process_state_dict(\n\u001b[1;32m    936\u001b[0m     state_dict,\n\u001b[1;32m    937\u001b[0m     fold_ln\u001b[38;5;241m=\u001b[39mfold_ln,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    941\u001b[0m     refactor_factored_attn_matrices\u001b[38;5;241m=\u001b[39mrefactor_factored_attn_matrices,\n\u001b[1;32m    942\u001b[0m )\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m move_to_device:\n\u001b[0;32m--> 945\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove_model_modules_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded pretrained model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into HookedTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/transformer_lens/HookedTransformer.py:793\u001b[0m, in \u001b[0;36mHookedTransformer.move_model_modules_to_device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mln_final\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_final\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    791\u001b[0m         devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    792\u001b[0m     )\n\u001b[0;32m--> 793\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munembed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_for_block_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[1;32m    797\u001b[0m     block\u001b[38;5;241m.\u001b[39mto(devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg))\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 50.06 GB, other allocations: 31.39 GB, max allowed: 81.60 GB). Tried to allocate 196.32 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2-medium\"\n",
    "model = measuring.load_model(model_name=model_name, device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851768c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_bias_context_pairs(df, pair_type=\"bias\"):\n",
    "    \n",
    "    prompt = \"The relationship between {ent1} and {ent2} is\"\n",
    "    pos_prefix = \"{ent1} loves {ent2}.\"\n",
    "    neg_prefix = \"{ent1} hates {ent2}.\"\n",
    "    \n",
    "    ent1_ent2 = list(zip(df[\"ent1\"].to_list(), df[\"ent2\"].to_list()))\n",
    "    \n",
    "    if pair_type==\"bias\":\n",
    "        ent1_ent2_pairs = []\n",
    "        entPair1_entPair2 = list(itertools.combinations(ent1_ent2, 2)) #permutations\n",
    "        for entPair1, entPair2 in entPair1_entPair2:\n",
    "            entPair1 = measuring.form_prompt(prompt,{\"ent1\":entPair1[0],\"ent2\":entPair1[1]})\n",
    "            entPair2 = measuring.form_prompt(prompt,{\"ent1\":entPair2[0],\"ent2\":entPair2[1]})\n",
    "            ent1_ent2_pairs.append((entPair1, entPair2))\n",
    "        \n",
    "    elif pair_type==\"context\":\n",
    "        ent1_ent2_pairs = []\n",
    "        for ent1, ent2 in ent1_ent2:\n",
    "            no_context_prompt = measuring.form_prompt(f\"{prompt}\", {\"ent1\": ent1, \"ent2\": ent2})\n",
    "            pos_context = measuring.form_prompt(f\"{pos_prefix} {prompt}\", {\"ent1\": ent1, \"ent2\": ent2})\n",
    "            neg_context = measuring.form_prompt(f\"{neg_prefix} {prompt}\", {\"ent1\": ent1, \"ent2\": ent2})\n",
    "\n",
    "            ent1_ent2_pairs.append((no_context_prompt, pos_context))\n",
    "            ent1_ent2_pairs.append((no_context_prompt, neg_context))\n",
    "        \n",
    "    print(f\"pair_type: {pair_type} --> {len(ent1_ent2_pairs)} data points\")\n",
    "    return ent1_ent2_pairs\n",
    "\n",
    "scales = [\"positive\", \"negative\"]\n",
    "scale_idx = measuring.get_logit_indices(scales, model)\n",
    "\n",
    "df = synth_data.load_synth_data(n=5, seed=10)\n",
    "prompt_pairs = construct_bias_context_pairs(df, pair_type=\"context\")\n",
    "prompt_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a659b",
   "metadata": {},
   "source": [
    "## Activation Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0617afe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 49.87 GB, other allocations: 31.74 GB, max allowed: 81.60 GB). Tried to allocate 50.00 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m old_logits, old_activs \u001b[38;5;241m=\u001b[39m measuring\u001b[38;5;241m.\u001b[39mprompt_with_cache(model,old_prompt,logit_idx\u001b[38;5;241m=\u001b[39mscale_idx,norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m new_logits, new_activs \u001b[38;5;241m=\u001b[39m measuring\u001b[38;5;241m.\u001b[39mprompt_with_cache(model,new_prompt,logit_idx\u001b[38;5;241m=\u001b[39mscale_idx,norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 56\u001b[0m vector_scale, vector_dir \u001b[38;5;241m=\u001b[39m \u001b[43mpatch_activs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_activs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m plot_heatmap(vector_scale\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatching Effect\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[62], line 27\u001b[0m, in \u001b[0;36mpatch_activs\u001b[0;34m(model, old_logits, new_logits, new_activs, old_prompt, logit_idx)\u001b[0m\n\u001b[1;32m     25\u001b[0m hook_layer_name \u001b[38;5;241m=\u001b[39m transformer_lens\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mget_act_name(hook_name, layer)\n\u001b[1;32m     26\u001b[0m patch_layers_fn \u001b[38;5;241m=\u001b[39m [(hook_layer_name, partial(patch_hook_point, new_activs\u001b[38;5;241m=\u001b[39mnew_activs, hook_layer_name\u001b[38;5;241m=\u001b[39mhook_layer_name))]\n\u001b[0;32m---> 27\u001b[0m patched_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfwd_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_layers_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreset_hooks_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m## get measurement change\u001b[39;00m\n\u001b[1;32m     30\u001b[0m patched_logits \u001b[38;5;241m=\u001b[39m measuring\u001b[38;5;241m.\u001b[39mselect_logits(patched_logits,logit_idx,norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/transformer_lens/hook_points.py:357\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_hooks\u001b[0;34m(self, fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: Hooks will be reset at the end of run_with_hooks. This removes the backward hooks before a backward pass can occur.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    352\u001b[0m     )\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(\n\u001b[1;32m    355\u001b[0m     fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts\n\u001b[1;32m    356\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m hooked_model:\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhooked_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/transformer_lens/HookedTransformer.py:365\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    362\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    363\u001b[0m         )\n\u001b[0;32m--> 365\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each block\u001b[39;49;00m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/transformer_lens/components.py:964\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m add_head_dimension(shortformer_pos_embed)\n\u001b[1;32m    960\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_out(\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m--> 964\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m    974\u001b[0m     resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(\n\u001b[1;32m    975\u001b[0m         resid_pre \u001b[38;5;241m+\u001b[39m attn_out\n\u001b[1;32m    976\u001b[0m     )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/transformer_lens/components.py:514\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask)\u001b[0m\n\u001b[1;32m    502\u001b[0m     qkv_einops_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_q(\n\u001b[1;32m    505\u001b[0m     einsum(\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqkv_einops_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, head_index d_model d_head \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_Q\n\u001b[1;32m    512\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[1;32m    513\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_k(\n\u001b[0;32m--> 514\u001b[0m     \u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mqkv_einops_string\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, head_index d_model d_head \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;43m        -> batch pos head_index d_head\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_K\n\u001b[1;32m    521\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[1;32m    522\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_v(\n\u001b[1;32m    523\u001b[0m     einsum(\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqkv_einops_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, head_index d_model d_head \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_V\n\u001b[1;32m    530\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_kv_cache_entry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;66;03m# Appends the new keys and values to the cached values, and automatically updates the cache\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/fancy_einsum/__init__.py:136\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    134\u001b[0m backend \u001b[38;5;241m=\u001b[39m get_backend(operands[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    135\u001b[0m new_equation \u001b[38;5;241m=\u001b[39m convert_equation(equation)\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_equation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/fancy_einsum/__init__.py:54\u001b[0m, in \u001b[0;36mTorchBackend.einsum\u001b[0;34m(self, equation, *operands)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(\u001b[38;5;28mself\u001b[39m, equation, \u001b[38;5;241m*\u001b[39moperands):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/torch/functional.py:378\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    380\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 49.87 GB, other allocations: 31.74 GB, max allowed: 81.60 GB). Tried to allocate 50.00 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "def patch_hook_point(patch_activs, hook: HookPoint, new_activs, hook_layer_name, extract_tok_idx=-1, insert_tok_idx=None):\n",
    "    #print(f'patching {hook.name} <-- {hook_layer_name}')\n",
    "    if extract_tok_idx is None or extract_tok_idx == -1:\n",
    "        extract_tok_idx = (0, -1)\n",
    "    if insert_tok_idx is None:\n",
    "        insert_tok_idx = extract_tok_idx\n",
    "    new_activs_hook = new_activs[hook_layer_name]\n",
    "    vector_direction.append(torch.stack([new_activs_hook[extract_tok_idx], patch_activs[insert_tok_idx]]))\n",
    "    patch_activs[insert_tok_idx] = new_activs_hook[extract_tok_idx]\n",
    "\n",
    "\n",
    "def patch_activs(model, old_logits, new_logits, new_activs, old_prompt, logit_idx):\n",
    "    \n",
    "    n_layers = model.cfg.n_layers\n",
    "    activ_d = model.cfg.d_model\n",
    "    hook_names = [\"attn_out\", \"mlp_out\"]\n",
    "    \n",
    "    effect_strength = torch.zeros(n_layers,len(hook_names), device=model.cfg.device)\n",
    "    global vector_direction\n",
    "    vector_direction = [] \n",
    "\n",
    "    for layer in (range(n_layers)):\n",
    "        for hook_i, hook_name in enumerate(hook_names): \n",
    "\n",
    "            hook_layer_name = transformer_lens.utils.get_act_name(hook_name, layer)\n",
    "            patch_layers_fn = [(hook_layer_name, partial(patch_hook_point, new_activs=new_activs, hook_layer_name=hook_layer_name))]\n",
    "            patched_logits = model.run_with_hooks(old_prompt,fwd_hooks=patch_layers_fn,reset_hooks_end=True)\n",
    "            \n",
    "            ## get measurement change\n",
    "            patched_logits = measuring.select_logits(patched_logits,logit_idx,norm=False)\n",
    "            patched_logit_diff = (patched_logits[...,0]-patched_logits[...,1])\n",
    "            \n",
    "            ## store effect strength\n",
    "            old_logit_diff = (old_logits[...,0]-old_logits[...,1])\n",
    "            new_logit_diff = (new_logits[...,0]-new_logits[...,1])\n",
    "            effect_strength[layer, hook_i] = torch.abs((patched_logit_diff-old_logit_diff)) / torch.abs((new_logit_diff-old_logit_diff))\n",
    "            #effect_strength[layer, hook_i] = torch.abs(patched_logits[...,0]-old_logits[...,0])\n",
    "            \n",
    "    vector_direction = torch.stack(vector_direction) \n",
    "    vector_direction = torch.movedim(vector_direction,0,1)\n",
    "    vector_direction = vector_direction.view(2,model.cfg.n_layers,-1,model.cfg.d_model)\n",
    "    return effect_strength.detach(), vector_direction.detach()\n",
    "        \n",
    "\n",
    "new_prompt = [\"Harry Potter loves Ronald Weasley. The relationship between Harry Potter and Ronald Weasley is\"]\n",
    "old_prompt = [\"The relationship between Harry Potter and Ronald Weasley is\"]\n",
    "#old_prompt = [\"The relationship between Jack and Mary is\"]\n",
    "\n",
    "#new_prompt = [\"Democrats like Republicans. The relationship between Democrats and Republicans is\"]\n",
    "new_prompt = [\"The relationship between Democrats and Republicans is\"]\n",
    "old_prompt = [\"The relationship between Harry and Ron is\"]\n",
    "\n",
    "old_logits, old_activs = measuring.prompt_with_cache(model,old_prompt,logit_idx=scale_idx,norm=False)\n",
    "new_logits, new_activs = measuring.prompt_with_cache(model,new_prompt,logit_idx=scale_idx,norm=False)\n",
    "\n",
    "vector_scale, vector_dir = patch_activs(model, old_logits, new_logits, new_activs, old_prompt, scale_idx)\n",
    "plot_heatmap(vector_scale.cpu().numpy(), title='Patching Effect', cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1262d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_patching_loop(model, prompt_pairs, scale_idx):\n",
    "    \n",
    "    all_vector_scale, all_vector_dir = [],[]    \n",
    "    for (prompt_1, prompt_2) in tqdm(prompt_pairs, position=0): \n",
    "        \n",
    "        old_logits, old_activs = measuring.prompt_with_cache(model,prompt_1,logit_idx=scale_idx)\n",
    "        new_logits, new_activs = measuring.prompt_with_cache(model,prompt_2,logit_idx=scale_idx)\n",
    "        vector_scale, vector_dir = patch_activs(model, old_logits, new_logits, new_activs, prompt_1, scale_idx)        \n",
    "        \n",
    "        all_vector_scale.append(vector_scale)\n",
    "        all_vector_dir.append(vector_dir)\n",
    "\n",
    "    vector_scale = torch.stack(all_vector_scale).detach() ## shape: prompt, layers, att vs mlp\n",
    "    vector_scale = vector_scale.mean(0)\n",
    "    vector_dir = torch.stack(all_vector_dir).detach() ## shape: prompt, new vs old, layers, att vs mlp, emb dim \n",
    "    return vector_scale, vector_dir\n",
    "        \n",
    "vector_scale, vector_dir = run_patching_loop(model, prompt_pairs, scale_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91488165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_heatmap(array, title='', xticklabels=[\"attn_out\", \"mlp_out\"], cmap=\"binary\"):\n",
    "    titlefont, labelsize=12, 10\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2, 4), gridspec_kw={'hspace': 0.4})\n",
    "    ax = sns.heatmap(array, cmap=mpl.colormaps[cmap], xticklabels=xticklabels, square=False)\n",
    "    ax.set_title(title, fontsize=titlefont, color=\"black\", loc='center',  y=1.1)\n",
    "    ax.set_ylabel('layers', fontsize=labelsize)\n",
    "    \n",
    "    mean_effect = list(map(lambda x: \"%.3f\" % x, list(array.max(0))))\n",
    "    for i, x_tick_label in enumerate(ax.get_xticklabels()):\n",
    "        ax.text(x_tick_label.get_position()[0]-0.5, -0.2, f\"max:\\n{mean_effect[i]}\", fontsize=labelsize, color=\"black\", verticalalignment='bottom')\n",
    "    plt.show()\n",
    "    \n",
    "plot_heatmap(vector_scale.cpu().numpy(), title='Patching Effect', cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea76442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 24, 2, 1024])\n",
      "torch.Size([2, 1024])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 2048 elements, which is inconsistent with 'x' and 'y' with size 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m a \u001b[38;5;241m=\u001b[39m vector_dir[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mdim_reduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 19\u001b[0m, in \u001b[0;36mdim_reduction\u001b[0;34m(embs, reduction)\u001b[0m\n\u001b[1;32m     16\u001b[0m     x_2D \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(x)\n\u001b[1;32m     18\u001b[0m fig, (ax) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m), gridspec_kw\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.40\u001b[39m})\n\u001b[0;32m---> 19\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_2D\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_2D\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/matplotlib/__init__.py:1446\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1446\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1448\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1449\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1450\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4596\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edgecolors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4594\u001b[0m     orig_edgecolor \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   4595\u001b[0m c, colors, edgecolors \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m-> 4596\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_scatter_color_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_next_color_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_patches_for_fill\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_color\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plotnonfinite \u001b[38;5;129;01mand\u001b[39;00m colors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4601\u001b[0m     c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mmasked_invalid(c)\n",
      "File \u001b[0;32m~/Code/measureLM/measureLM_venv/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4449\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[1;32m   4445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(colors) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, xsize):\n\u001b[1;32m   4447\u001b[0m             \u001b[38;5;66;03m# NB: remember that a single color is also acceptable.\u001b[39;00m\n\u001b[1;32m   4448\u001b[0m             \u001b[38;5;66;03m# Besides *colors* will be an empty array if c == 'none'.\u001b[39;00m\n\u001b[0;32m-> 4449\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m invalid_shape_exception(\u001b[38;5;28mlen\u001b[39m(colors), xsize)\n\u001b[1;32m   4450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4451\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# use cmap, norm after collection is created\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: 'c' argument has 2048 elements, which is inconsistent with 'x' and 'y' with size 2."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def dim_reduction(embs, reduction=\"pca\"):\n",
    "    \n",
    "    x = embs.view(-1, embs.shape[-1]).cpu().detach().numpy()\n",
    "    \n",
    "    y_len = int((embs.shape[0] * embs.shape[1])/2)\n",
    "    y = ([0] * y_len + [1] * y_len)\n",
    "    colormap = np.array(['g', 'r'])\n",
    "    y = colormap[y]\n",
    "    \n",
    "    if reduction == \"pca\":\n",
    "        pca = PCA(n_components=2)\n",
    "        x_2D = pca.fit_transform(x)\n",
    "        \n",
    "    fig, (ax) = plt.subplots(1, figsize=(5, 5), gridspec_kw={'hspace': 0.40})\n",
    "    ax.scatter(x_2D[:, 0], x_2D[:, 1], c=y)\n",
    "    plt.show()\n",
    "    \n",
    "print(vector_dir.shape)\n",
    "#dim_reduction(vector_dir.mean(0)[...,0,:].cpu())\n",
    "a = vector_dir[...,0,:].mean(-2)\n",
    "print(a.shape)\n",
    "dim_reduction(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f13c75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "measureLM_venv",
   "language": "python",
   "name": "measurelm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
