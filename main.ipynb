{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Susceptibility Scores\n",
    "A notebook for initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/mambaforge/envs/measurelm2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from measuring.estimate_probs import estimate_cmi\n",
    "from preprocessing.datasets import CountryCapital, FriendEnemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "##################\n",
    "### Parameters ###\n",
    "##################\n",
    "\n",
    "# Data parameters\n",
    "SEED = 0\n",
    "DATASET_NAME = \"CountryCapital\"\n",
    "DATASET_KWARGS_IDENTIFIABLE = dict(\n",
    "    max_contexts=15,\n",
    "    max_entities=5,\n",
    "    cap_per_type=True,\n",
    "    raw_country_capitals_path=\"data/CountryCapital/real-fake-historical-fictional-famousfictional-country-capital.csv\",\n",
    "    ablate_out_relevant_contexts=True,\n",
    ")\n",
    "# DATASET_KWARGS_IDENTIFIABLE = dict(\n",
    "#     max_contexts=450,\n",
    "#     max_entities=90,\n",
    "#     cap_per_type=True,\n",
    "#     raw_country_capitals_path=\"data/CountryCapital/real-fake-historical-fictional-famousfictional-country-capital.csv\",\n",
    "#     ablate_out_relevant_contexts=True,\n",
    "# )\n",
    "# DATASET_NAME = \"FriendEnemy\"\n",
    "# DATASET_KWARGS_IDENTIFIABLE = dict(\n",
    "#     max_contexts=15,\n",
    "#     max_entities=5,\n",
    "#     cap_per_type=False,\n",
    "#     raw_data_path=\"data/FriendEnemy/raw-friend-enemy.csv\",\n",
    "# )\n",
    "# DATASET_KWARGS_IDENTIFIABLE = dict(\n",
    "#     max_contexts=657,\n",
    "#     max_entities=73,\n",
    "#     cap_per_type=False,\n",
    "#     raw_data_path=\"data/FriendEnemy/raw-friend-enemy.csv\",\n",
    "# )\n",
    "LOG_DATASETS = True\n",
    "\n",
    "# Model parameters\n",
    "MODEL_ID = \"EleutherAI/pythia-70m-deduped\"\n",
    "LOAD_IN_8BIT = False\n",
    "# MODEL_ID = \"EleutherAI/pythia-6.9b-deduped\"\n",
    "# LOAD_IN_8BIT = True\n",
    "BATCH_SZ = 16\n",
    "\n",
    "# Evaluation switches\n",
    "COMPUTE_CMI = True\n",
    "COMPUTE_KL = True\n",
    "COMPUTE_GOOD_BAD = True\n",
    "COMPUTE_GOOD_BAD_ABS = True\n",
    "COMPUTE_GOOD_BAD_P_GOOD_ONLY = True\n",
    "\n",
    "# wandb stuff\n",
    "PROJECT_NAME = \"context-vs-bias\"\n",
    "GROUP_NAME = None\n",
    "TAGS = [\"capitals\"]\n",
    "# TAGS = [\"friend-enemy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dir: data/CountryCapital/CountryCapital-mc15-me5-cappertype/0\n",
      "Model dir: data/CountryCapital/CountryCapital-mc15-me5-cappertype/0/models/EleutherAI/pythia-70m-deduped\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "# Construct dataset and data ids\n",
    "# dataset = getattr(sys.modules[__name__], DATASET_NAME)(**DATASET_KWARGS_IDENTIFIABLE)\n",
    "data_id = f\"{DATASET_NAME}\"\n",
    "data_id += (\n",
    "    f\"-mc{DATASET_KWARGS_IDENTIFIABLE['max_contexts']}\"\n",
    "    if \"max_contexts\" in DATASET_KWARGS_IDENTIFIABLE\n",
    "    and DATASET_KWARGS_IDENTIFIABLE[\"max_contexts\"] is not None\n",
    "    else \"\"\n",
    ")\n",
    "data_id += (\n",
    "    f\"-me{DATASET_KWARGS_IDENTIFIABLE['max_entities']}\"\n",
    "    if \"max_entities\" in DATASET_KWARGS_IDENTIFIABLE\n",
    "    and DATASET_KWARGS_IDENTIFIABLE[\"max_entities\"] is not None\n",
    "    else \"\"\n",
    ")\n",
    "data_id += (\n",
    "    \"-cappertype\"\n",
    "    if \"cap_per_type\" in DATASET_KWARGS_IDENTIFIABLE\n",
    "    and DATASET_KWARGS_IDENTIFIABLE[\"cap_per_type\"]\n",
    "    else \"\"\n",
    ")\n",
    "\n",
    "\n",
    "data_dir = os.path.join(\"data\", DATASET_NAME, data_id, f\"{SEED}\")\n",
    "input_dir = os.path.join(data_dir, \"inputs\")\n",
    "entities_path = os.path.join(input_dir, \"entities.json\")\n",
    "contexts_path = os.path.join(input_dir, \"contexts.json\")\n",
    "queries_path = os.path.join(input_dir, \"queries.json\")\n",
    "val_data_path = os.path.join(input_dir, \"val.csv\")\n",
    "DATASET_KWARGS_IDENTIFIABLE = {\n",
    "    **DATASET_KWARGS_IDENTIFIABLE,\n",
    "    **dict(\n",
    "        entities_path=entities_path,\n",
    "        contexts_path=contexts_path,\n",
    "        queries_path=queries_path,\n",
    "    ),\n",
    "}\n",
    "\n",
    "results_dir = os.path.join(data_dir, \"results\")\n",
    "val_results_path = os.path.join(results_dir, \"val.csv\")\n",
    "\n",
    "# Construct model id\n",
    "model_id = f\"{MODEL_ID}\"\n",
    "model_id += \"-8bit\" if LOAD_IN_8BIT else \"\"\n",
    "model_dir = os.path.join(data_dir, \"models\", model_id)\n",
    "\n",
    "print(f\"Data dir: {data_dir}\")\n",
    "print(f\"Model dir: {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "dataset = getattr(sys.modules[__name__], DATASET_NAME)(**DATASET_KWARGS_IDENTIFIABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU stuff\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkdu\u001b[0m (\u001b[33methz-rycolab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kevin/code/rycolab/measureLM/wandb/run-20231220_002039-cc4y8bts</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ethz-rycolab/context-vs-bias/runs/cc4y8bts' target=\"_blank\">fresh-moon-59</a></strong> to <a href='https://wandb.ai/ethz-rycolab/context-vs-bias' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ethz-rycolab/context-vs-bias' target=\"_blank\">https://wandb.ai/ethz-rycolab/context-vs-bias</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ethz-rycolab/context-vs-bias/runs/cc4y8bts' target=\"_blank\">https://wandb.ai/ethz-rycolab/context-vs-bias/runs/cc4y8bts</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SEED': 0, 'DATASET_NAME': 'CountryCapital', 'DATASET_KWARGS_IDENTIFIABLE': {'max_contexts': 15, 'max_entities': 5, 'cap_per_type': True, 'raw_country_capitals_path': 'data/CountryCapital/real-fake-historical-fictional-famousfictional-country-capital.csv', 'ablate_out_relevant_contexts': True, 'entities_path': 'data/CountryCapital/CountryCapital-mc15-me5-cappertype/0/inputs/entities.json', 'contexts_path': 'data/CountryCapital/CountryCapital-mc15-me5-cappertype/0/inputs/contexts.json', 'queries_path': 'data/CountryCapital/CountryCapital-mc15-me5-cappertype/0/inputs/queries.json'}, 'LOG_DATASETS': True, 'MODEL_ID': 'EleutherAI/pythia-70m-deduped', 'LOAD_IN_8BIT': False, 'BATCH_SZ': 16, 'COMPUTE_CMI': True, 'COMPUTE_KL': True, 'COMPUTE_GOOD_BAD': True, 'COMPUTE_GOOD_BAD_ABS': True, 'COMPUTE_GOOD_BAD_P_GOOD_ONLY': True, 'PROJECT_NAME': 'context-vs-bias', 'GROUP_NAME': None, 'TAGS': ['capitals']}\n"
     ]
    }
   ],
   "source": [
    "# wandb stuff\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = os.path.join(os.getcwd(), \"main.ipynb\")\n",
    "\n",
    "params_to_log = {k: v for k, v in locals().items() if k.isupper()}\n",
    "\n",
    "run = wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    group=GROUP_NAME,\n",
    "    config=params_to_log,\n",
    "    tags=TAGS,\n",
    "    mode=\"online\",\n",
    ")\n",
    "print(dict(wandb.config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving datasets to data/CountryCapital/CountryCapital-mc15-me5-cappertype/0/inputs.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   q_id        10 non-null     object\n",
      " 1   query_form  10 non-null     object\n",
      " 2   entity      10 non-null     object\n",
      " 3   contexts    10 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>query_form</th>\n",
       "      <th>entity</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>Q: What is the capital of {}?\\nA:</td>\n",
       "      <td>(Zimbabwe,)</td>\n",
       "      <td>[The capital of Part of Kingdom of Sicily is A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>Q: What is the capital of {}?\\nA:</td>\n",
       "      <td>(The Sticklands,)</td>\n",
       "      <td>[The capital of Part of Kingdom of Sicily is A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>Q: What is the capital of {}?\\nA:</td>\n",
       "      <td>(Jakana,)</td>\n",
       "      <td>[The capital of Part of Kingdom of Sicily is A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>Q: What is the capital of {}?\\nA:</td>\n",
       "      <td>(Mordor,)</td>\n",
       "      <td>[The capital of Part of Kingdom of Sicily is A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>Q: What is the capital of {}?\\nA:</td>\n",
       "      <td>(Baekje,)</td>\n",
       "      <td>[The capital of Part of Kingdom of Sicily is A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         q_id                         query_form             entity  \\\n",
       "0  capital_of  Q: What is the capital of {}?\\nA:        (Zimbabwe,)   \n",
       "1  capital_of  Q: What is the capital of {}?\\nA:  (The Sticklands,)   \n",
       "2  capital_of  Q: What is the capital of {}?\\nA:          (Jakana,)   \n",
       "3  capital_of  Q: What is the capital of {}?\\nA:          (Mordor,)   \n",
       "4  capital_of  Q: What is the capital of {}?\\nA:          (Baekje,)   \n",
       "\n",
       "                                            contexts  \n",
       "0  [The capital of Part of Kingdom of Sicily is A...  \n",
       "1  [The capital of Part of Kingdom of Sicily is A...  \n",
       "2  [The capital of Part of Kingdom of Sicily is A...  \n",
       "3  [The capital of Part of Kingdom of Sicily is A...  \n",
       "4  [The capital of Part of Kingdom of Sicily is A...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_contexts_per_qe = dataset.get_contexts_per_query_entity_df()\n",
    "\n",
    "if LOG_DATASETS:\n",
    "    print(f\"Saving datasets to {input_dir}.\")\n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    val_df_contexts_per_qe.to_csv(val_data_path)\n",
    "\n",
    "val_df_contexts_per_qe.info()\n",
    "val_df_contexts_per_qe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data and convert it into inputs for the model (e.g. torch tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/CountryCapital/CountryCapital-mc15-me5-cappertype/0)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging datasets to w&b run <wandb.sdk.wandb_run.Run object at 0x7f89e480c2b0>.\n"
     ]
    }
   ],
   "source": [
    "# After loading/preprocessing your dataset, log it as an artifact to W&B\n",
    "if LOG_DATASETS:\n",
    "    print(f\"Logging datasets to w&b run {wandb.run}.\")\n",
    "    artifact = wandb.Artifact(name=data_id, type=\"dataset\")\n",
    "    artifact.add_dir(local_path=data_dir)\n",
    "    run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load model EleutherAI/pythia-70m-deduped in 8-bit. Attempting to load normally.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/kevin/code/rycolab/measureLM/main.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model \u001b[39m=\u001b[39m GPTNeoXForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         MODEL_ID, load_in_8bit\u001b[39m=\u001b[39;49mLOAD_IN_8BIT, device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/measurelm2/lib/python3.10/site-packages/transformers/modeling_utils.py:3396\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3395\u001b[0m \u001b[39mif\u001b[39;00m device_map \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msequential\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 3396\u001b[0m     max_memory \u001b[39m=\u001b[39m get_balanced_memory(\n\u001b[1;32m   3397\u001b[0m         model,\n\u001b[1;32m   3398\u001b[0m         dtype\u001b[39m=\u001b[39;49mtarget_dtype,\n\u001b[1;32m   3399\u001b[0m         low_zero\u001b[39m=\u001b[39;49m(device_map \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mbalanced_low_0\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   3400\u001b[0m         max_memory\u001b[39m=\u001b[39;49mmax_memory,\n\u001b[1;32m   3401\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdevice_map_kwargs,\n\u001b[1;32m   3402\u001b[0m     )\n\u001b[1;32m   3403\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/measurelm2/lib/python3.10/site-packages/accelerate/utils/modeling.py:771\u001b[0m, in \u001b[0;36mget_balanced_memory\u001b[0;34m(model, max_memory, no_split_module_classes, dtype, special_dtypes, low_zero)\u001b[0m\n\u001b[1;32m    770\u001b[0m user_not_set_max_memory \u001b[39m=\u001b[39m max_memory \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 771\u001b[0m max_memory \u001b[39m=\u001b[39m get_max_memory(max_memory)\n\u001b[1;32m    773\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_xpu_available():\n",
      "File \u001b[0;32m~/mambaforge/envs/measurelm2/lib/python3.10/site-packages/accelerate/utils/modeling.py:643\u001b[0m, in \u001b[0;36mget_max_memory\u001b[0;34m(max_memory)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()):\n\u001b[0;32m--> 643\u001b[0m     _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m0\u001b[39;49m], device\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    644\u001b[0m max_memory \u001b[39m=\u001b[39m {i: torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mmem_get_info(i)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count())}\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/kevin/code/rycolab/measureLM/main.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to load model \u001b[39m\u001b[39m{\u001b[39;00mMODEL_ID\u001b[39m}\u001b[39;00m\u001b[39m in 8-bit. Attempting to load normally.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model \u001b[39m=\u001b[39m GPTNeoXForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         MODEL_ID,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         load_in_8bit\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     )\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     MODEL_ID,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     padding_side\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevin/code/rycolab/measureLM/main.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/measurelm2/lib/python3.10/site-packages/transformers/modeling_utils.py:2271\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m     \u001b[39mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2267\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2268\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2269\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2270\u001b[0m         )\n\u001b[0;32m-> 2271\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/measurelm2/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/mambaforge/envs/measurelm2/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/measurelm2/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/measurelm2/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/mambaforge/envs/measurelm2/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = GPTNeoXForCausalLM.from_pretrained(\n",
    "        MODEL_ID, load_in_8bit=LOAD_IN_8BIT, device_map=\"auto\"\n",
    "    )\n",
    "except:\n",
    "    print(f\"Failed to load model {MODEL_ID} in 8-bit. Attempting to load normally.\")\n",
    "    model = GPTNeoXForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        load_in_8bit=False,\n",
    "    ).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    padding_side=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory.used [MiB]\n",
      "879 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=memory.used --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1824"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting model.config.pad_token_id to model.config.eos_token_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/code/rycolab/measureLM/measuring/estimate_probs.py:275: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.sum(prob_x_y_given_e * np.nan_to_num(np.log(prob_y_given_context_and_entity / prob_y_given_e)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.020289460580657594"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One forward pass\n",
    "row = val_df_contexts_per_qe.iloc[0]\n",
    "estimate_cmi(\n",
    "    row[\"query_form\"],\n",
    "    entity=row[\"entity\"],\n",
    "    contexts=row[\"contexts\"][:128],\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    bs=BATCH_SZ,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/code/rycolab/measureLM/measuring/estimate_probs.py:275: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.sum(prob_x_y_given_e * np.nan_to_num(np.log(prob_y_given_context_and_entity / prob_y_given_e)))\n",
      " 40%|████      | 4/10 [00:00<00:00, 32.33it/s]/home/kevin/code/rycolab/measureLM/measuring/estimate_probs.py:275: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(prob_x_y_given_e * np.nan_to_num(np.log(prob_y_given_context_and_entity / prob_y_given_e)))\n",
      "100%|██████████| 10/10 [00:00<00:00, 25.08it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "val_df_contexts_per_qe[\"susceptibility_score\"] = val_df_contexts_per_qe.progress_apply(\n",
    "    lambda row: estimate_cmi(\n",
    "        query=row[\"query_form\"],\n",
    "        entity=row[\"entity\"],\n",
    "        contexts=row[\"contexts\"],\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        answer_map=None,\n",
    "        bs=BATCH_SZ,\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "val_df_contexts_per_qe.to_csv(val_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/CountryCapital/CountryCapital-mc15-me5-cappertype/0)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging results to w&b run <wandb.sdk.wandb_run.Run object at 0x7fd45e01fe20>.\n"
     ]
    }
   ],
   "source": [
    "# After loading/preprocessing your dataset, log it as an artifact to W&B\n",
    "if LOG_DATASETS:\n",
    "    print(f\"Logging results to w&b run {wandb.run}.\")\n",
    "    artifact = wandb.Artifact(name=data_id, type=\"dataset\")\n",
    "    artifact.add_dir(local_path=data_dir)\n",
    "    run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity\n",
       "(Zimbabwe,)          2\n",
       "(The Sticklands,)    2\n",
       "(Jakana,)            2\n",
       "(Mordor,)            2\n",
       "(Baekje,)            2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_contexts_per_qe[\"entity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>query_form</th>\n",
       "      <th>entity</th>\n",
       "      <th>contexts</th>\n",
       "      <th>susceptibility_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>The capital of {} is</td>\n",
       "      <td>(Zimbabwe,)</td>\n",
       "      <td>[The capital of Baekje is Doha.\\n, The capital...</td>\n",
       "      <td>0.400978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>The capital of {} is</td>\n",
       "      <td>(The Sticklands,)</td>\n",
       "      <td>[The capital of Baekje is Doha.\\n, The capital...</td>\n",
       "      <td>0.479788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>The capital of {} is</td>\n",
       "      <td>(Mordor,)</td>\n",
       "      <td>[The capital of Baekje is Doha.\\n, The capital...</td>\n",
       "      <td>0.568573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>The capital of {} is</td>\n",
       "      <td>(Baekje,)</td>\n",
       "      <td>[The capital of Baekje is Doha.\\n, The capital...</td>\n",
       "      <td>0.648642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>The capital of {} is</td>\n",
       "      <td>(Jakana,)</td>\n",
       "      <td>[The capital of Baekje is Doha.\\n, The capital...</td>\n",
       "      <td>0.651999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         q_id            query_form             entity  \\\n",
       "5  capital_of  The capital of {} is        (Zimbabwe,)   \n",
       "6  capital_of  The capital of {} is  (The Sticklands,)   \n",
       "8  capital_of  The capital of {} is          (Mordor,)   \n",
       "9  capital_of  The capital of {} is          (Baekje,)   \n",
       "7  capital_of  The capital of {} is          (Jakana,)   \n",
       "\n",
       "                                            contexts  susceptibility_score  \n",
       "5  [The capital of Baekje is Doha.\\n, The capital...              0.400978  \n",
       "6  [The capital of Baekje is Doha.\\n, The capital...              0.479788  \n",
       "8  [The capital of Baekje is Doha.\\n, The capital...              0.568573  \n",
       "9  [The capital of Baekje is Doha.\\n, The capital...              0.648642  \n",
       "7  [The capital of Baekje is Doha.\\n, The capital...              0.651999  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_contexts_per_qe[\n",
    "    val_df_contexts_per_qe[\"query_form\"] == \"The capital of {} is\"\n",
    "].sort_values(by=\"susceptibility_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>query_form</th>\n",
       "      <th>entity</th>\n",
       "      <th>contexts</th>\n",
       "      <th>susceptibility_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>Q: What is the capital of {}?\\nA:</td>\n",
       "      <td>(Zimbabwe,)</td>\n",
       "      <td>[The capital of Baekje is Doha.\\n, The capital...</td>\n",
       "      <td>0.020289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>Q: What is the capital of {}?\\nA:</td>\n",
       "      <td>(Baekje,)</td>\n",
       "      <td>[The capital of Baekje is Doha.\\n, The capital...</td>\n",
       "      <td>0.036602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>Q: What is the capital of {}?\\nA:</td>\n",
       "      <td>(Jakana,)</td>\n",
       "      <td>[The capital of Baekje is Doha.\\n, The capital...</td>\n",
       "      <td>0.047524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>Q: What is the capital of {}?\\nA:</td>\n",
       "      <td>(Mordor,)</td>\n",
       "      <td>[The capital of Baekje is Doha.\\n, The capital...</td>\n",
       "      <td>0.059646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>capital_of</td>\n",
       "      <td>Q: What is the capital of {}?\\nA:</td>\n",
       "      <td>(The Sticklands,)</td>\n",
       "      <td>[The capital of Baekje is Doha.\\n, The capital...</td>\n",
       "      <td>0.068201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         q_id                         query_form             entity  \\\n",
       "0  capital_of  Q: What is the capital of {}?\\nA:        (Zimbabwe,)   \n",
       "4  capital_of  Q: What is the capital of {}?\\nA:          (Baekje,)   \n",
       "2  capital_of  Q: What is the capital of {}?\\nA:          (Jakana,)   \n",
       "3  capital_of  Q: What is the capital of {}?\\nA:          (Mordor,)   \n",
       "1  capital_of  Q: What is the capital of {}?\\nA:  (The Sticklands,)   \n",
       "\n",
       "                                            contexts  susceptibility_score  \n",
       "0  [The capital of Baekje is Doha.\\n, The capital...              0.020289  \n",
       "4  [The capital of Baekje is Doha.\\n, The capital...              0.036602  \n",
       "2  [The capital of Baekje is Doha.\\n, The capital...              0.047524  \n",
       "3  [The capital of Baekje is Doha.\\n, The capital...              0.059646  \n",
       "1  [The capital of Baekje is Doha.\\n, The capital...              0.068201  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_contexts_per_qe[\n",
    "    val_df_contexts_per_qe[\"query_form\"] == \"Q: What is the capital of {}?\\nA:\"\n",
    "].sort_values(by=\"susceptibility_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 12.6%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-eon-45</strong> at: <a href='https://wandb.ai/ethz-rycolab/context-vs-bias/runs/wxzhg0xj' target=\"_blank\">https://wandb.ai/ethz-rycolab/context-vs-bias/runs/wxzhg0xj</a><br/> View job at <a href='https://wandb.ai/ethz-rycolab/context-vs-bias/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMjczNzY4NA==/version_details/v7' target=\"_blank\">https://wandb.ai/ethz-rycolab/context-vs-bias/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMjczNzY4NA==/version_details/v7</a><br/>Synced 7 W&B file(s), 0 media file(s), 14 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231218_170242-wxzhg0xj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "measurelm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
